# -*- coding: utf-8 -*-
"""
ëŒ€í”¼ì†Œ / ì¬ë‚œ ì•ˆì „ ì±—ë´‡ ì„±ëŠ¥ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

í‰ê°€ ì§€í‘œ:
1. Intent Accuracy (ì˜ë„ ë¶„ë¥˜ ì •í™•ë„)
2. Recall@K (ëŒ€í”¼ì†Œ/ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ì¬í˜„ìœ¨)
3. Tool Execution Accuracy (ë„êµ¬ ì‹¤í–‰ ì •í™•ë„)
4. Structured Data Validation (êµ¬ì¡°í™”ëœ ë°ì´í„° ê²€ì¦)
5. End-to-End Latency (ì‘ë‹µ ì‹œê°„)

ì‹¤í–‰:
$ python chatbot_eval_new.py
"""

import os
import time
import json
from statistics import mean
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ==============================
# 1. í‰ê°€ í…ŒìŠ¤íŠ¸ì…‹ ì •ì˜
# ==============================

# Intent í…ŒìŠ¤íŠ¸ì…‹ (í˜„ì¬ 8ê°€ì§€ ì˜ë„ ë¶„ë¥˜ì— ë§ê²Œ ì—…ë°ì´íŠ¸)
INTENT_TESTSET = [
    # shelter_location: ìœ„ì¹˜ ê¸°ë°˜ ëŒ€í”¼ì†Œ ê²€ìƒ‰
    ("ê°•ë‚¨ì—­ ê·¼ì²˜ ëŒ€í”¼ì†Œ ì•Œë ¤ì¤˜", "shelter_location"),
    ("ëª…ë™ ì£¼ë³€ ëŒ€í”¼ì†Œ ì°¾ì•„ì¤˜", "shelter_location"),
    ("í•œë¼ì‚° ê·¼ì²˜ ëŒ€í”¼ì†Œ", "shelter_location"),
    ("ì„œìš¸ì—­ ì£¼ë³€ ëŒ€í”¼ì†Œ", "shelter_location"),
    
    # shelter_count: ëŒ€í”¼ì†Œ ê°œìˆ˜ í†µê³„
    ("ì„œìš¸ì— ëŒ€í”¼ì†Œ ëª‡ ê°œì•¼?", "shelter_count"),
    ("ì œì£¼ë„ ëŒ€í”¼ì†Œ ê°œìˆ˜ ì•Œë ¤ì¤˜", "shelter_count"),
    ("ê°•ë‚¨êµ¬ ëŒ€í”¼ì†Œ ìˆ˜", "shelter_count"),
    ("ë¶€ì‚° ëŒ€í”¼ì†Œ ëª‡ ê°œ?", "shelter_count"),
    
    # shelter_capacity: ìˆ˜ìš©ì¸ì› ê¸°ë°˜ ê²€ìƒ‰
    ("1000ëª… ì´ìƒ ìˆ˜ìš© ê°€ëŠ¥í•œ ê³³", "shelter_capacity"),
    ("500ëª… ìˆ˜ìš©í•  ìˆ˜ ìˆëŠ” ëŒ€í”¼ì†Œ", "shelter_capacity"),
    ("5000ëª… ì´ìƒ ëŒ€í”¼ì†Œ", "shelter_capacity"),
    ("3000ëª… ì´ìƒ ìˆ˜ìš©", "shelter_capacity"),
    ("ë™ëŒ€ë¬¸ë§¨ì…˜ ìˆ˜ìš©ì¸ì› ì•Œë ¤ì¤˜", "shelter_capacity"),
    
    # disaster_guideline: ì¬ë‚œ í–‰ë™ìš”ë ¹
    ("íƒœí’ ì˜¬ ë•Œ ë­í•´ì•¼ í•˜ì§€?", "disaster_guideline"),
    ("ì§€ì§„ ë°œìƒ ì‹œ ëŒ€ì²˜ë²•", "disaster_guideline"),
    ("í™”ì¬ ë‚¬ì„ ë•Œ í–‰ë™ìš”ë ¹", "disaster_guideline"),
    ("í™ìˆ˜ ë°œìƒ ì‹œ ëŒ€í”¼ ë°©ë²•", "disaster_guideline"),
    
    # general_knowledge: ì¬ë‚œ ê°œë…/ì •ì˜
    ("ì§€ì§„ì´ë€ ë­ì•¼?", "general_knowledge"),
    ("íƒœí’ì˜ ì •ì˜ê°€ ë­ì•¼?", "general_knowledge"),
    ("ì‚°ì‚¬íƒœëŠ” ì™œ ë°œìƒí•´?", "general_knowledge"),
    ("ì“°ë‚˜ë¯¸ë€?", "general_knowledge"),
    
    # shelter_name: íŠ¹ì • ì‹œì„¤ëª…ìœ¼ë¡œ ê²€ìƒ‰
    ("ì„œìš¸ì—­ ëŒ€í”¼ì†Œ ì •ë³´", "shelter_name"),
    ("ë¡¯ë°ì›”ë“œíƒ€ì›Œ ëŒ€í”¼ì†Œ", "shelter_name"),
    ("ë™ì•„ì•„íŒŒíŠ¸ ì •ë³´", "shelter_name"),
    ("ì œì£¼ë„ì˜ ë™ì•„ì•„íŒŒíŠ¸ ì •ë³´", "shelter_name"),
    
    # location_with_disaster: ìœ„ì¹˜ + ì¬ë‚œ ë³µí•© ì§ˆë¬¸
    ("ê°•ë‚¨ì—­ì—ì„œ ì§€ì§„ ë‚˜ë©´ ì–´ë–»ê²Œ í•´?", "location_with_disaster"),
    ("ëª…ë™ í™”ì¬ ë‚¬ì„ ë•Œ ëŒ€í”¼ì†Œ", "location_with_disaster"),
    ("ì ì‹¤ ë¡¯ë°íƒ€ì›Œì— ë¶ˆ ë‚¬ì–´", "location_with_disaster"),
    ("ì„¤ì•…ì‚° ê·¼ì²˜ì¸ë° ì‚°ì‚¬íƒœ ë°œìƒ", "location_with_disaster"),
    
    # general_chat: ì¼ìƒ ëŒ€í™”
    ("ì•ˆë…•?", "general_chat"),
    ("ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?", "general_chat"),
    ("ì˜ ì§€ë‚´?", "general_chat"),
    ("ê³ ë§ˆì›Œ", "general_chat"),
]

# Guideline Recall í…ŒìŠ¤íŠ¸ì…‹
# expected_keywordê°€ Noneì¸ ê²½ìš°: VectorDBì— í•´ë‹¹ ì¬ë‚œ ê°€ì´ë“œë¼ì¸ì´ ì—†ì–´ì„œ ê²€ìƒ‰ ì‹¤íŒ¨ê°€ ì˜ˆìƒë˜ëŠ” ì¼€ì´ìŠ¤
GUIDELINE_RECALL_TESTSET = [
    ("ì§€ì§„ ë°œìƒ ì‹œ í–‰ë™ìš”ë ¹", "ì§€ì§„"),
    ("ì‚°ì‚¬íƒœ ëŒ€í”¼ ë°©ë²•", "ì‚°ì‚¬íƒœ"),
    ("íƒœí’ ëŒ€ë¹„ ìš”ë ¹", "íƒœí’"),
    ("í™”ì¬ ë°œìƒ ì‹œ ëŒ€ì²˜ë²•", "í™”ì¬"),
    ("í™ìˆ˜ ë°œìƒ ì‹œ í–‰ë™ìš”ë ¹", "í™ìˆ˜"),
    ("ì“°ë‚˜ë¯¸ ë°œìƒ ì‹œ ëŒ€í”¼", "í•´ì¼"),
    ("í™”ì‚° í­ë°œ ëŒ€ì²˜ë²•", "í™”ì‚°"),
    ("ë°©ì‚¬ëŠ¥ ëˆ„ì¶œ ëŒ€ì‘", None),  # VectorDBì— ì—†ëŠ” ê°€ì´ë“œë¼ì¸ (ê²€ìƒ‰ ì‹¤íŒ¨ ì˜ˆìƒ)
    ("í­ì—¼ ëŒ€ë¹„ ë°©ë²•", None),     # VectorDBì— ì—†ëŠ” ê°€ì´ë“œë¼ì¸ (ê²€ìƒ‰ ì‹¤íŒ¨ ì˜ˆìƒ)
    ("í•œíŒŒ ëŒ€ì²˜ ìš”ë ¹", None),     # VectorDBì— ì—†ëŠ” ê°€ì´ë“œë¼ì¸ (ê²€ìƒ‰ ì‹¤íŒ¨ ì˜ˆìƒ)
    ("ëˆˆì‚¬íƒœ ë°œìƒ ì‹œ í–‰ë™", None), # VectorDBì— ì—†ëŠ” ê°€ì´ë“œë¼ì¸ (ê²€ìƒ‰ ì‹¤íŒ¨ ì˜ˆìƒ)
]

# Latency í…ŒìŠ¤íŠ¸ì…‹ (ì‘ë‹µ ì‹œê°„ ì¸¡ì •)
LATENCY_TESTSET = [
    "ì„œìš¸ì—­ ê·¼ì²˜ ëŒ€í”¼ì†Œ ì•Œë ¤ì¤˜",
    "ë¶€ì‚°ì— ëŒ€í”¼ì†Œ ëª‡ ê°œì•¼?",
    "500ëª… ìˆ˜ìš© ê°€ëŠ¥í•œ ê³³",
    "í™”ì¬ ë°œìƒ ì‹œ í–‰ë™ìš”ë ¹",
    "ê°•ë‚¨ì—­ì—ì„œ ì§€ì§„ ë‚˜ë©´?",
    "ë™ëŒ€ë¬¸ë§¨ì…˜ ì •ë³´",
    "ì œì£¼ë„ ëŒ€í”¼ì†Œ ìˆ˜",
    "1000ëª… ì´ìƒ ëŒ€í”¼ì†Œ",
    "ì§€ì§„ì´ë€ ë­ì•¼?",
    "ì•ˆë…•?",
]

# ë„êµ¬ë³„ í…ŒìŠ¤íŠ¸ì…‹ (structured_data ê²€ì¦ìš©)
# expected_tools: ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì • (ì—¬ëŸ¬ ë„êµ¬ê°€ í˜¸ì¶œë  ìˆ˜ ìˆìŒ)
TOOL_TESTSET = [
    {
        "query": "ê°•ë‚¨ì—­ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_tools": ["search_shelter_by_location"],
        "should_have_structured_data": True,
        "structured_data_keys": ["shelters"]
    },
    {
        "query": "ì„œìš¸ì— ëŒ€í”¼ì†Œ ëª‡ ê°œ?",
        "expected_tools": ["count_shelters"],
        "should_have_structured_data": False,
        "structured_data_keys": None
    },
    {
        "query": "1000ëª… ì´ìƒ ëŒ€í”¼ì†Œ",
        "expected_tools": ["search_shelter_by_capacity"],
        "should_have_structured_data": True,
        "structured_data_keys": ["shelters"]
    },
    {
        "query": "ì§€ì§„ ë°œìƒ ì‹œ í–‰ë™ìš”ë ¹",
        "expected_tools": ["search_disaster_guideline"],
        "should_have_structured_data": False,
        "structured_data_keys": None
    },
    {
        "query": "ë™ëŒ€ë¬¸ë§¨ì…˜ ìˆ˜ìš©ì¸ì›",
        "expected_tools": ["search_shelter_by_name"],
        "should_have_structured_data": True,
        "structured_data_keys": ["shelters"]
    },
    {
        "query": "ê°•ë‚¨ì—­ì—ì„œ ì§€ì§„ ë‚˜ë©´?",
        "expected_tools": ["search_location_with_disaster"],  # ë˜ëŠ” ["search_shelter_by_location", "search_disaster_guideline"]
        "should_have_structured_data": True,
        "structured_data_keys": ["shelters"]
    },
    {
        "query": "ì ì‹¤ ë¡¯ë°íƒ€ì›Œì— ë¶ˆ ë‚¬ì–´",
        "expected_tools": ["search_location_with_disaster"],  # ì—¬ëŸ¬ ë„êµ¬ ìˆœì°¨ í˜¸ì¶œ ê°€ëŠ¥
        "should_have_structured_data": True,
        "structured_data_keys": ["shelters"]
    },
    {
        "query": "ì§€ì§„ì´ë€ ë­ì•¼?",
        "expected_tools": ["answer_general_knowledge"],
        "should_have_structured_data": False,
        "structured_data_keys": None
    },
    {
        "query": "ì•ˆë…•?",
        "expected_tools": [],
        "should_have_structured_data": False,
        "structured_data_keys": None
    },
]

# ë²”ìš©ì  í–‰ì •êµ¬ì—­ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ì…‹
# query_rewrite í›„ Kakao APIë¡œ ì¢Œí‘œ ë³€í™˜ â†’ ëŒ€í”¼ì†Œ ê²€ìƒ‰ íë¦„ í…ŒìŠ¤íŠ¸
ADDRESS_MATCHING_TESTSET = [
    {
        "query": "ì œì£¼ë„ ë™ì•„ì•„íŒŒíŠ¸",
        "expected_min_results": 1,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (íŠ¹ë³„ìì¹˜ë„)"
    },
    {
        "query": "ì„œìš¸ ê°•ë‚¨êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 10,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (íŠ¹ë³„ì‹œ)"
    },
    {
        "query": "ë¶€ì‚° í•´ìš´ëŒ€êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 5,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ê´‘ì—­ì‹œ)"
    },
    {
        "query": "ëŒ€ì „ ìœ ì„±êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 3,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ê´‘ì—­ì‹œ êµ¬)"
    },
    {
        "query": "ê´‘ì£¼ ë¶êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 2,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ê´‘ì—­ì‹œ êµ¬)"
    },
    {
        "query": "ì¸ì²œ ë‚¨ë™êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 4,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ê´‘ì—­ì‹œ êµ¬)"
    },
    {
        "query": "ê°•ì›ë„ ì†ì´ˆì‹œ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 2,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ë„ ë‹¨ìœ„)"
    },
    {
        "query": "ê²½ê¸°ë„ ì„±ë‚¨ì‹œ ë¶„ë‹¹êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 5,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ì‹œ êµ¬ ë‹¨ìœ„)"
    },
    {
        "query": "ìš¸ì‚° ë‚¨êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 3,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ê´‘ì—­ì‹œ êµ¬)"
    },
    {
        "query": "ì „ë¼ë¶ë„ ì „ì£¼ì‹œ ì™„ì‚°êµ¬ ê·¼ì²˜ ëŒ€í”¼ì†Œ",
        "expected_min_results": 2,
        "description": "ì¿¼ë¦¬ ì¬ì •ì˜ í›„ Kakao API ì¢Œí‘œ ë³€í™˜ í…ŒìŠ¤íŠ¸ (ë„ ì‹œ êµ¬ ë‹¨ìœ„)"
    },
]

# ==============================
# 2. Intent Accuracy í…ŒìŠ¤íŠ¸
# ==============================

def test_intent_accuracy(intent_chain):
    """ì˜ë„ ë¶„ë¥˜ ì •í™•ë„ ì¸¡ì •"""
    print("\n" + "="*50)
    print("Intent Accuracy í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    correct = 0
    total = len(INTENT_TESTSET)
    failures = []
    
    for query, expected_intent in INTENT_TESTSET:
        try:
            raw = intent_chain.invoke({"query": query})
            parsed = json.loads(raw)
            predicted_intent = parsed.get("intent", "unknown")
            
            if predicted_intent == expected_intent:
                correct += 1
                print(f"âœ… [{query}] â†’ {predicted_intent}")
            else:
                failures.append({
                    "query": query,
                    "expected": expected_intent,
                    "predicted": predicted_intent
                })
                print(f"âŒ [{query}] ì˜ˆìƒ: {expected_intent}, ì‹¤ì œ: {predicted_intent}")
        except Exception as e:
            failures.append({
                "query": query,
                "expected": expected_intent,
                "error": str(e)
            })
            print(f"âš ï¸ [{query}] ì˜¤ë¥˜: {e}")
    
    accuracy = correct / total if total > 0 else 0
    
    print(f"\n[Intent Accuracy] {accuracy:.2%} ({correct}/{total})")
    
    if failures:
        print("\nì‹¤íŒ¨ ì¼€ì´ìŠ¤:")
        for f in failures:
            print(f"  - {f}")
    
    return accuracy, failures


# ==============================
# 3. Recall@K í…ŒìŠ¤íŠ¸
# ==============================

def test_recall_at_k(retriever, testset, k=5):
    """Retrieverì˜ Recall@K ì¸¡ì •
    
    expected_keywordê°€ Noneì¸ ê²½ìš°: VectorDBì— í•´ë‹¹ ë¬¸ì„œê°€ ì—†ì–´ì„œ ê²€ìƒ‰ ì‹¤íŒ¨ê°€ ì˜ˆìƒë¨ (ì •ìƒ)
    """
    print("\n" + "="*50)
    print(f"Recall@{k} í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    hit = 0
    total = len(testset)
    failures = []
    
    for query, expected_keyword in testset:
        # VectorDBì— ì—†ëŠ” ê°€ì´ë“œë¼ì¸ì€ í…ŒìŠ¤íŠ¸ì—ì„œ ì œì™¸ (None)
        if expected_keyword is None:
            print(f"âšª [{query}] â†’ VectorDBì— ì—†ëŠ” ê°€ì´ë“œë¼ì¸ (í…ŒìŠ¤íŠ¸ ì œì™¸)")
            total -= 1  # ì „ì²´ ì¹´ìš´íŠ¸ì—ì„œ ì œì™¸
            continue
        
        try:
            docs = retriever.invoke(query)
            top_k = docs[:k]
            
            found = any(expected_keyword in d.page_content for d in top_k)
            
            if found:
                hit += 1
                print(f"âœ… [{query}] â†’ '{expected_keyword}' ë°œê²¬")
            else:
                failures.append({
                    "query": query,
                    "expected_keyword": expected_keyword,
                    "retrieved_docs": [d.page_content[:100] for d in top_k]
                })
                print(f"âŒ [{query}] â†’ '{expected_keyword}' ë¯¸ë°œê²¬")
        except Exception as e:
            failures.append({
                "query": query,
                "expected_keyword": expected_keyword,
                "error": str(e)
            })
            print(f"âš ï¸ [{query}] ì˜¤ë¥˜: {e}")
    
    recall = hit / total if total > 0 else 0
    
    print(f"\n[Recall@{k}] {recall:.2%} ({hit}/{total})")
    
    if failures:
        print("\nì‹¤íŒ¨ ì¼€ì´ìŠ¤:")
        for f in failures:
            print(f"  - Query: {f.get('query')}")
            print(f"    Expected: {f.get('expected_keyword')}")
            if 'error' in f:
                print(f"    Error: {f['error']}")
    
    return recall, failures


# ==============================
# 4. Tool Execution Accuracy í…ŒìŠ¤íŠ¸
# ==============================

def test_tool_execution(langgraph_app):
    """ë„êµ¬ ì‹¤í–‰ ì •í™•ë„ ë° structured_data ê²€ì¦
    
    ì£¼ì˜: LangGraph AgentëŠ” ì—¬ëŸ¬ ë²ˆ ë°˜ë³µë˜ë©´ì„œ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ
    ì˜ˆ: "ê°•ë‚¨ì—­ì—ì„œ ì§€ì§„ ë‚˜ë©´?" â†’ search_location_with_disaster ë˜ëŠ”
        search_shelter_by_location + search_disaster_guideline
    """
    print("\n" + "="*50)
    print("Tool Execution Accuracy í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    correct = 0
    total = len(TOOL_TESTSET)
    failures = []
    
    for i, test_case in enumerate(TOOL_TESTSET):
        query = test_case["query"]
        expected_tools = test_case["expected_tools"]  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€ê²½
        should_have_structured_data = test_case["should_have_structured_data"]
        structured_data_keys = test_case["structured_data_keys"]
        
        try:
            # LangGraph App ì‹¤í–‰
            result = langgraph_app.invoke(
                {"messages": [HumanMessage(content=query)]},
                config={"configurable": {"thread_id": f"tool_test_{i}"}}
            )
            
            # ë„êµ¬ í˜¸ì¶œ í™•ì¸ (ëª¨ë“  ë©”ì‹œì§€ì—ì„œ tool_calls ìˆ˜ì§‘)
            messages = result.get("messages", [])
            tool_calls = []
            for msg in messages:
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    tool_calls.extend([tc['name'] for tc in msg.tool_calls])
            
            # structured_data í™•ì¸
            structured_data = result.get("structured_data")
            
            # ê²€ì¦ 1: ë„êµ¬ í˜¸ì¶œ ì—¬ë¶€
            # ê°™ì€ ë„êµ¬ê°€ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ setìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
            unique_tool_calls = set(tool_calls)
            
            # expected_toolsê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° (ì¼ë°˜ ì±„íŒ…): ë„êµ¬ê°€ í˜¸ì¶œë˜ì§€ ì•Šì•„ì•¼ í•¨
            if len(expected_tools) == 0:
                tool_match = len(tool_calls) == 0
            else:
                # ì˜ˆìƒëœ ë„êµ¬ ì¤‘ í•˜ë‚˜ë¼ë„ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
                tool_match = any(tool in unique_tool_calls for tool in expected_tools)
            
            # ê²€ì¦ 2: structured_data ê²€ì¦ (ë„êµ¬ê°€ ì œëŒ€ë¡œ í˜¸ì¶œëœ ê²½ìš°ì—ë§Œ)
            data_match = True
            if should_have_structured_data:
                # structured_dataê°€ ìˆì–´ì•¼ í•˜ëŠ” ê²½ìš°
                if structured_data is None:
                    data_match = False
                elif structured_data_keys:
                    # íŠ¹ì • í‚¤ê°€ ìˆì–´ì•¼ í•˜ëŠ” ê²½ìš°
                    data_match = all(key in structured_data for key in structured_data_keys)
            # should_have_structured_dataê°€ Falseì¸ ê²½ìš°ëŠ” ê²€ì¦í•˜ì§€ ì•ŠìŒ (data_match = True ìœ ì§€)
            
            # ìµœì¢… íŒì •: ë„êµ¬ í˜¸ì¶œì´ ë§ìœ¼ë©´ í†µê³¼ (structured_dataëŠ” ê²½ê³ ë§Œ)
            # tool_matchë§Œìœ¼ë¡œ íŒì •í•˜ê³ , data_matchëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
            if tool_match:
                correct += 1
                if data_match:
                    print(f"âœ… [{query}]")
                    print(f"   ì˜ˆìƒ ë„êµ¬: {expected_tools}")
                    print(f"   í˜¸ì¶œëœ ë„êµ¬: {tool_calls} (ê³ ìœ : {list(unique_tool_calls)})")
                    print(f"   ë°ì´í„°: {'ìˆìŒ' if structured_data else 'ì—†ìŒ'}")
                else:
                    print(f"âš ï¸ [{query}] - ë„êµ¬ í˜¸ì¶œ ì„±ê³µ, ë°ì´í„° ëˆ„ë½")
                    print(f"   ì˜ˆìƒ ë„êµ¬: {expected_tools}")
                    print(f"   í˜¸ì¶œëœ ë„êµ¬: {tool_calls} (ê³ ìœ : {list(unique_tool_calls)})")
                    print(f"   ê²½ê³ : structured_dataê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„ ({structured_data})")
            else:
                failures.append({
                    "query": query,
                    "expected_tools": expected_tools,
                    "called_tools": tool_calls,
                    "unique_tools": list(unique_tool_calls),
                    "tool_match": tool_match,
                    "data_match": data_match,
                    "structured_data": structured_data
                })
                print(f"âŒ [{query}]")
                print(f"   ì˜ˆìƒ ë„êµ¬: {expected_tools}")
                print(f"   í˜¸ì¶œëœ ë„êµ¬: {tool_calls} (ê³ ìœ : {list(unique_tool_calls)})")
                print(f"   ë„êµ¬ ë§¤ì¹­: {tool_match}")
                print(f"   ë°ì´í„° ë§¤ì¹­: {data_match}")
                print(f"   structured_data: {structured_data}")
        
        except Exception as e:
            failures.append({
                "query": query,
                "expected_tools": expected_tools,
                "error": str(e)
            })
            print(f"âš ï¸ [{query}] ì˜¤ë¥˜: {e}")
    
    accuracy = correct / total if total > 0 else 0
    
    print(f"\n[Tool Execution Accuracy] {accuracy:.2%} ({correct}/{total})")
    
    if failures:
        print("\nì‹¤íŒ¨ ì¼€ì´ìŠ¤:")
        for f in failures:
            print(f"  - Query: {f.get('query')}")
            print(f"    Expected: {f.get('expected_tools')}")
            print(f"    Called: {f.get('called_tools')}")
            print(f"    Unique: {f.get('unique_tools')}")
            if 'error' in f:
                print(f"    Error: {f['error']}")
    
    return accuracy, failures


# ==============================
# 5. Address Matching í…ŒìŠ¤íŠ¸
# ==============================

def test_address_matching(langgraph_app):
    """ë²”ìš©ì  í–‰ì •êµ¬ì—­ ë§¤ì¹­ í…ŒìŠ¤íŠ¸
    
    í…ŒìŠ¤íŠ¸ íë¦„:
    1. ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
    2. intent_classifier: ì˜ë„ ë¶„ë¥˜
    3. query_rewrite: ì§€ëª… ì¶”ì¶œ ë° ì¿¼ë¦¬ ì¬ì •ì˜
    4. search_shelter_by_location: ì¬ì •ì˜ëœ ì¿¼ë¦¬ë¡œ Kakao API í˜¸ì¶œ â†’ ì¢Œí‘œ ë³€í™˜
    5. ì¢Œí‘œ ê¸°ë°˜ ëŒ€í”¼ì†Œ ê²€ìƒ‰ ë° structured_data ë°˜í™˜
    
    ê²€ì¦: Kakao APIê°€ ë‹¤ì–‘í•œ í–‰ì •êµ¬ì—­ í‘œí˜„ì„ ì •í™•íˆ ì¢Œí‘œë¡œ ë³€í™˜í•˜ëŠ”ì§€ í™•ì¸
    """
    print("\n" + "="*50)
    print("Address Matching í…ŒìŠ¤íŠ¸ (Query Rewrite â†’ Kakao API)")
    print("="*50)
    
    correct = 0
    total = len(ADDRESS_MATCHING_TESTSET)
    failures = []
    
    for i, test_case in enumerate(ADDRESS_MATCHING_TESTSET):
        query = test_case["query"]
        expected_min_results = test_case["expected_min_results"]
        description = test_case["description"]
        
        try:
            result = langgraph_app.invoke(
                {"messages": [HumanMessage(content=query)]},
                config={"configurable": {"thread_id": f"address_test_{i}"}}
            )
            
            # ë””ë²„ê¹…: ê²°ê³¼ êµ¬ì¡° í™•ì¸
            messages = result.get("messages", [])
            structured_data = result.get("structured_data")
            
            # ë„êµ¬ í˜¸ì¶œ í™•ì¸
            tool_calls = []
            for msg in messages:
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    tool_calls.extend([tc['name'] for tc in msg.tool_calls])
            
            # ë„êµ¬ ë©”ì‹œì§€ì—ì„œ structured_data í™•ì¸ (tools_nodeì˜ ì‘ë‹µ)
            tool_messages = [msg for msg in messages if hasattr(msg, 'name') and msg.name]
            
            # structured_dataê°€ Noneì´ì–´ë„ ë‹µë³€ì´ ì œëŒ€ë¡œ ë‚˜ì™”ëŠ”ì§€ í™•ì¸
            last_message = messages[-1] if messages else None
            has_response = last_message and hasattr(last_message, 'content') and len(last_message.content) > 0
            
            # ì„±ê³µ íŒì •: structured_dataê°€ ìˆê±°ë‚˜, ë„êµ¬ê°€ í˜¸ì¶œë˜ê³  ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì„±ê³µ
            if structured_data and "shelters" in structured_data:
                # ì¼€ì´ìŠ¤ 1: structured_dataê°€ ì œëŒ€ë¡œ ìˆëŠ” ê²½ìš°
                num_results = len(structured_data["shelters"])
                
                if num_results >= expected_min_results:
                    correct += 1
                    print(f"âœ… [{description}]")
                    print(f"   ì¿¼ë¦¬: {query}")
                    print(f"   ê²°ê³¼: {num_results}ê°œ (ìµœì†Œ {expected_min_results}ê°œ ì˜ˆìƒ)")
                    print(f"   structured_data: ì •ìƒ")
                else:
                    failures.append({
                        "query": query,
                        "description": description,
                        "expected_min": expected_min_results,
                        "actual": num_results
                    })
                    print(f"âŒ [{description}]")
                    print(f"   ì¿¼ë¦¬: {query}")
                    print(f"   ê²°ê³¼: {num_results}ê°œ (ìµœì†Œ {expected_min_results}ê°œ ì˜ˆìƒ)")
            elif 'search_shelter_by_location' in tool_calls and has_response:
                # ì¼€ì´ìŠ¤ 2: structured_dataëŠ” ì—†ì§€ë§Œ ë„êµ¬ê°€ í˜¸ì¶œë˜ê³  ë‹µë³€ì´ ìƒì„±ë¨ (ì •ìƒ ì‘ë™)
                correct += 1
                print(f"âœ… [{description}] - ë„êµ¬ í˜¸ì¶œ ì„±ê³µ, ë‹µë³€ ìƒì„±ë¨")
                print(f"   ì¿¼ë¦¬: {query}")
                print(f"   í˜¸ì¶œëœ ë„êµ¬: {tool_calls}")
                print(f"   ë‹µë³€ ê¸¸ì´: {len(last_message.content) if last_message else 0}ì")
                print(f"   âš ï¸ structured_dataëŠ” Noneì´ì§€ë§Œ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™")
            else:
                # ì¼€ì´ìŠ¤ 3: ë„êµ¬ í˜¸ì¶œë„ ì•ˆë˜ê³  ë‹µë³€ë„ ì—†ìŒ (ì‹¤íŒ¨)
                failures.append({
                    "query": query,
                    "description": description,
                    "error": "structured_data ì—†ìŒ",
                    "tool_calls": tool_calls,
                    "has_response": has_response,
                    "structured_data": structured_data
                })
                print(f"âŒ [{description}] â†’ ì‹¤íŒ¨")
                print(f"   ì¿¼ë¦¬: {query}")
                print(f"   í˜¸ì¶œëœ ë„êµ¬: {tool_calls}")
                print(f"   ë‹µë³€ ìƒì„±: {has_response}")
                print(f"   structured_data: {structured_data}")
        
        except Exception as e:
            failures.append({
                "query": query,
                "description": description,
                "error": str(e)
            })
            print(f"âš ï¸ [{description}] ì˜¤ë¥˜: {e}")
    
    accuracy = correct / total if total > 0 else 0
    
    print(f"\n[Address Matching Accuracy] {accuracy:.2%} ({correct}/{total})")
    
    if failures:
        print("\nì‹¤íŒ¨ ì¼€ì´ìŠ¤:")
        for f in failures:
            print(f"  - Query: {f.get('query')}")
            print(f"    Description: {f.get('description')}")
            if 'actual' in f:
                print(f"    Expected Min: {f['expected_min']}, Actual: {f['actual']}")
            if 'error' in f:
                print(f"    Error: {f['error']}")
    
    return accuracy, failures
    
    return accuracy, failures


# ==============================
# 6. End-to-End Latency í…ŒìŠ¤íŠ¸
# ==============================

def test_latency(langgraph_app):
    """End-to-End ì‘ë‹µ ì‹œê°„ ì¸¡ì •"""
    print("\n" + "="*50)
    print("End-to-End Latency í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    times = []
    
    for i, query in enumerate(LATENCY_TESTSET):
        try:
            start = time.time()
            langgraph_app.invoke(
                {"messages": [HumanMessage(content=query)]},
                config={"configurable": {"thread_id": f"latency_test_{i}"}}
            )
            elapsed = (time.time() - start) * 1000
            times.append(elapsed)
            
            print(f"âœ… [{query}] â†’ {elapsed:.1f}ms")
        
        except Exception as e:
            print(f"âš ï¸ [{query}] ì˜¤ë¥˜: {e}")
    
    if times:
        avg = mean(times)
        p50 = sorted(times)[int(len(times) * 0.50)]
        p95 = sorted(times)[int(len(times) * 0.95)]
        
        print(f"\n[Latency] avg={avg:.1f}ms | p50={p50:.1f}ms | p95={p95:.1f}ms")
        return avg, p50, p95
    else:
        print("\n[Latency] ì¸¡ì • ì‹¤íŒ¨")
        return 0, 0, 0


# ==============================
# 7. ì¢…í•© í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±
# ==============================

def generate_evaluation_report(results):
    """í‰ê°€ ê²°ê³¼ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\n" + "="*70)
    print("ğŸ“Š ì±—ë´‡ ì„±ëŠ¥ í‰ê°€ ì¢…í•© ë¦¬í¬íŠ¸")
    print("="*70)
    
    print("\n1ï¸âƒ£ Intent Accuracy (ì˜ë„ ë¶„ë¥˜ ì •í™•ë„)")
    print(f"   ì •í™•ë„: {results['intent_accuracy']:.2%}")
    print(f"   ì‹¤íŒ¨: {len(results['intent_failures'])}ê±´")
    
    print("\n2ï¸âƒ£ Recall@K (ê²€ìƒ‰ ì¬í˜„ìœ¨)")
    print(f"   Recall@5: {results['recall_at_k']:.2%}")
    print(f"   ì‹¤íŒ¨: {len(results['recall_failures'])}ê±´")
    
    print("\n3ï¸âƒ£ Tool Execution Accuracy (ë„êµ¬ ì‹¤í–‰ ì •í™•ë„)")
    print(f"   ì •í™•ë„: {results['tool_accuracy']:.2%}")
    print(f"   ì‹¤íŒ¨: {len(results['tool_failures'])}ê±´")
    
    print("\n4ï¸âƒ£ Address Matching Accuracy (ì£¼ì†Œ ë§¤ì¹­ ì •í™•ë„)")
    print(f"   ì •í™•ë„: {results['address_accuracy']:.2%}")
    print(f"   ì‹¤íŒ¨: {len(results['address_failures'])}ê±´")
    
    print("\n5ï¸âƒ£ Latency (ì‘ë‹µ ì‹œê°„)")
    print(f"   í‰ê· : {results['latency_avg']:.1f}ms")
    print(f"   P50: {results['latency_p50']:.1f}ms")
    print(f"   P95: {results['latency_p95']:.1f}ms")
    
    print("\n" + "="*70)
    print("âœ… í‰ê°€ ì™„ë£Œ")
    print("="*70)
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    with open("evaluation_report.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print("\nğŸ“ ìƒì„¸ ê²°ê³¼ê°€ 'evaluation_report.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================
# 8. ë©”ì¸ ì‹¤í–‰ë¶€
# ==============================

if __name__ == "__main__":
    print("\nğŸš€ ì±—ë´‡ ì„±ëŠ¥ í‰ê°€ ì‹œì‘\n")
    
    # í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ import
    from langgraph_agent import create_langgraph_app
    from langchain_chroma import Chroma
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    from langchain_core.output_parsers import StrOutputParser
    
    # VectorDB ë¡œë“œ
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = Chroma(
        collection_name="shelter_and_disaster_guidelines",
        embedding_function=embeddings,
        persist_directory="chroma_db"
    )
    
    # LangGraph App ìƒì„±
    app = create_langgraph_app(vectorstore)
    
    # Intent Chain ìƒì„± (langgraph_agent.pyì™€ ë™ì¼í•œ êµ¬ì¡°)
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    intent_prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ 8ê°€ì§€ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. shelter_location: ìœ„ì¹˜ ê¸°ë°˜ ëŒ€í”¼ì†Œ ê²€ìƒ‰ (ì˜ˆ: "ê°•ë‚¨ì—­ ê·¼ì²˜ ëŒ€í”¼ì†Œ")
2. shelter_count: ëŒ€í”¼ì†Œ ê°œìˆ˜ í†µê³„ (ì˜ˆ: "ì„œìš¸ì— ëŒ€í”¼ì†Œ ëª‡ ê°œ?")
3. shelter_capacity: ìˆ˜ìš©ì¸ì› ê¸°ë°˜ ê²€ìƒ‰ (ì˜ˆ: "1000ëª… ì´ìƒ ìˆ˜ìš©")
4. disaster_guideline: ì¬ë‚œ í–‰ë™ìš”ë ¹ (ì˜ˆ: "ì§€ì§„ ë°œìƒ ì‹œ ëŒ€ì²˜ë²•")
5. general_knowledge: ì¬ë‚œ ê°œë…/ì •ì˜ (ì˜ˆ: "ì§€ì§„ì´ë€?")
6. shelter_name: íŠ¹ì • ì‹œì„¤ëª… ê²€ìƒ‰ (ì˜ˆ: "ë™ëŒ€ë¬¸ë§¨ì…˜ ì •ë³´")
7. location_with_disaster: ìœ„ì¹˜ + ì¬ë‚œ ë³µí•© (ì˜ˆ: "ê°•ë‚¨ì—­ì—ì„œ ì§€ì§„ ë‚˜ë©´?")
8. general_chat: ì¼ìƒ ëŒ€í™” (ì˜ˆ: "ì•ˆë…•?")

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
{{"intent": "ë¶„ë¥˜ê²°ê³¼", "confidence": 0.95}}"""),
        ("human", "{query}")
    ])
    
    intent_chain = intent_prompt | llm | StrOutputParser()
    
    # Hybrid Retriever ìƒì„± (ì¬ë‚œ ê°€ì´ë“œë¼ì¸ìš©)
    from langgraph_agent import EnsembleRetriever
    from langchain_community.retrievers import BM25Retriever
    
    # ê°€ì´ë“œë¼ì¸ ë¬¸ì„œë§Œ í•„í„°ë§
    guideline_docs = vectorstore.similarity_search("", k=1000, filter={"type": "disaster_guideline"})
    
    bm25_retriever = BM25Retriever.from_documents(guideline_docs)
    bm25_retriever.k = 5
    
    vector_retriever = vectorstore.as_retriever(
        search_kwargs={"k": 5, "filter": {"type": "disaster_guideline"}}
    )
    
    guideline_hybrid = EnsembleRetriever(
        retrievers=[vector_retriever, bm25_retriever],
        weights=[0.6, 0.4]
    )
    
    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    results = {}
    
    # 1. Intent Accuracy í…ŒìŠ¤íŠ¸
    intent_accuracy, intent_failures = test_intent_accuracy(intent_chain)
    results['intent_accuracy'] = intent_accuracy
    results['intent_failures'] = intent_failures
    
    # 2. Recall@K í…ŒìŠ¤íŠ¸
    recall_at_k, recall_failures = test_recall_at_k(guideline_hybrid, GUIDELINE_RECALL_TESTSET, k=5)
    results['recall_at_k'] = recall_at_k
    results['recall_failures'] = recall_failures
    
    # 3. Tool Execution Accuracy í…ŒìŠ¤íŠ¸
    tool_accuracy, tool_failures = test_tool_execution(app)
    results['tool_accuracy'] = tool_accuracy
    results['tool_failures'] = tool_failures
    
    # 4. Address Matching í…ŒìŠ¤íŠ¸
    address_accuracy, address_failures = test_address_matching(app)
    results['address_accuracy'] = address_accuracy
    results['address_failures'] = address_failures
    
    # 5. Latency í…ŒìŠ¤íŠ¸
    latency_avg, latency_p50, latency_p95 = test_latency(app)
    results['latency_avg'] = latency_avg
    results['latency_p50'] = latency_p50
    results['latency_p95'] = latency_p95
    
    # 6. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    generate_evaluation_report(results)
    
    print("\nâœ… ì„±ëŠ¥ í‰ê°€ ì™„ë£Œ\n")
