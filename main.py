# -*- coding: utf-8 -*-
"""
ëŒ€í”¼ì†Œ ì•ˆë‚´ ì±—ë´‡ API ì„œë²„
FastAPI ê¸°ë°˜ ì›¹ API

=== í”„ë¡œì íŠ¸ ê°œìš” ===
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ëŒ€í”¼ì†Œ ì•ˆë‚´ ì±—ë´‡ì˜ ë°±ì—”ë“œ ì„œë²„ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
FastAPIë¥¼ ì‚¬ìš©í•˜ì—¬ REST APIë¥¼ ì œê³µí•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ì£¼ìš” ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤:
1. ì§€ëª… ì¶”ì¶œ ë° ëŒ€í”¼ì†Œ ê²€ìƒ‰
2. RAG (Retrieval-Augmented Generation) ê¸°ë°˜ ì¬ë‚œí–‰ë™ìš”ë ¹ ì•ˆë‚´
3. ëŒ€í”¼ì†Œ ë°ì´í„° ì¡°íšŒ (GPS ê¸°ë°˜ ê·¼ì²˜ ëŒ€í”¼ì†Œ)
4. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

=== ì‚¬ìš© ê¸°ìˆ  ìŠ¤íƒ ë° ì—­í•  ===

[ë°±ì—”ë“œ í”„ë ˆì„ì›Œí¬]
- FastAPI: ë¹„ë™ê¸° ì›¹ API ì„œë²„ í”„ë ˆì„ì›Œí¬
  * REST API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
  * Request/Response ë°ì´í„° ê²€ì¦ (Pydantic)
  * ìë™ API ë¬¸ì„œ ìƒì„± (Swagger UI)
  * CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
  * Lifespan ì´ë²¤íŠ¸ë¡œ ì„œë²„ ì´ˆê¸°í™”/ì¢…ë£Œ ê´€ë¦¬

[AI/LLM]
- OpenAI GPT-4o-mini: ìì—°ì–´ ì²˜ë¦¬ ë° ì˜ë„ ë¶„ë¥˜
  * ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ (ëŒ€í”¼ì†Œ ê²€ìƒ‰ / ì¬ë‚œí–‰ë™ìš”ë ¹ / ì¼ë°˜ ëŒ€í™”)
  * JSON ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ê²°ê³¼ ë°˜í™˜
  * Temperature=0 ì„¤ì •ìœ¼ë¡œ ì¼ê´€ëœ ë¶„ë¥˜ ê²°ê³¼ ë³´ì¥

- OpenAI Embeddings (text-embedding-3-small): í…ìŠ¤íŠ¸ ë²¡í„°í™”
  * ëŒ€í”¼ì†Œ ì •ë³´ ë° ì¬ë‚œí–‰ë™ìš”ë ¹ ë¬¸ì„œ ì„ë² ë”©
  * ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰ ì§€ì›

[ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤]
- ChromaDB: ë²¡í„° ì €ì¥ì†Œ ë° ìœ ì‚¬ë„ ê²€ìƒ‰
  * ëŒ€í”¼ì†Œ ë©”íƒ€ë°ì´í„° ì €ì¥ (ì‹œì„¤ëª…, ì£¼ì†Œ, ì¢Œí‘œ, ìˆ˜ìš©ì¸ì›)
  * ì¬ë‚œí–‰ë™ìš”ë ¹ ë¬¸ì„œ ì €ì¥ ë° ê²€ìƒ‰
  * ë©”íƒ€ë°ì´í„° í•„í„°ë§ (type: shelter / disaster_guideline)
  * Persist ë””ë ‰í† ë¦¬ë¥¼ í†µí•œ ì˜êµ¬ ì €ì¥

[LangChain]
- langchain-chroma: ChromaDBì™€ LangChain í†µí•©
  * Vector Store ì¶”ìƒí™” ê³„ì¸µ ì œê³µ
  * ë¬¸ì„œ ê²€ìƒ‰ ë° ìœ ì‚¬ë„ ê³„ì‚°
  
- langchain-openai: OpenAI ëª¨ë¸ LangChain í†µí•©
  * ì„ë² ë”© ëª¨ë¸ ë˜í¼ ì œê³µ

[ë°ì´í„° ì²˜ë¦¬]
- Pandas: ëŒ€í”¼ì†Œ CSV ë°ì´í„° ì²˜ë¦¬
  * ëŒ€í”¼ì†Œ ì •ë³´ DataFrame ê´€ë¦¬
  * ì¢Œí‘œ ê¸°ë°˜ í•„í„°ë§ ë° ì •ë ¬

[ì™¸ë¶€ API]
- ì¹´ì¹´ì˜¤ ë¡œì»¬ API (Kakao Local API): ì¥ì†Œ ê²€ìƒ‰ ë° ì¢Œí‘œ ë³€í™˜
  * í‚¤ì›Œë“œ ê²€ìƒ‰ì„ í†µí•œ ì§€ëª… â†’ ìœ„ê²½ë„ ì¢Œí‘œ ë³€í™˜
  * ì¹´í…Œê³ ë¦¬ ì •ë³´ë¡œ ëœë“œë§ˆí¬ ìš°ì„ ìˆœìœ„ íŒë‹¨
  * REST API ë°©ì‹ (requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)

[ë°ì´í„° ê²€ì¦]
- Pydantic: Request/Response ë°ì´í„° ëª¨ë¸ ì •ì˜
  * LocationExtractRequest: ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
  * LocationExtractResponse: ëŒ€í”¼ì†Œ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
  * BaseModel ìƒì†ìœ¼ë¡œ ìë™ ê²€ì¦ ë° ì§ë ¬í™”

[í™˜ê²½ ì„¤ì •]
- python-dotenv: í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬
  * .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ (OPENAI_API_KEY, KAKAO_REST_API_KEY)
  * ë¯¼ê° ì •ë³´ ì†ŒìŠ¤ì½”ë“œ ë¶„ë¦¬

[ì„œë²„ ì‹¤í–‰]
- Uvicorn: ASGI ì„œë²„
  * FastAPI ì•± ì‹¤í–‰
  * Hot reload ì§€ì› (ê°œë°œ ëª¨ë“œ)
  * SSL/TLS ì§€ì› (HTTPS ì„œë²„)

[ê±°ë¦¬ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜]
- Haversine Formula: êµ¬ë©´ìƒì˜ ë‘ ì  ì‚¬ì´ ìµœë‹¨ ê±°ë¦¬ ê³„ì‚°
  * ì‚¬ìš©ì ìœ„ì¹˜ â†” ëŒ€í”¼ì†Œ ìœ„ì¹˜ ê°„ ì§ì„  ê±°ë¦¬ (km)
  * ê°€ì¥ ê°€ê¹Œìš´ ëŒ€í”¼ì†Œ 5ê³³ ì¶”ì¶œ

[ì£¼ìš” ì²˜ë¦¬ íë¦„]
1. ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
2. LLM ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ (find_shelter / disaster_guide / general_chat)
3-1. ëŒ€í”¼ì†Œ ê²€ìƒ‰: ì¹´ì¹´ì˜¤ API â†’ ì¢Œí‘œ ë³€í™˜ â†’ ChromaDB ë©”íƒ€ë°ì´í„° â†’ Haversine ê±°ë¦¬ ê³„ì‚° â†’ ì •ë ¬
3-2. ì¬ë‚œí–‰ë™ìš”ë ¹: ChromaDB ìœ ì‚¬ë„ ê²€ìƒ‰ â†’ ê´€ë ¨ ë¬¸ì„œ ë°˜í™˜
4. JSON ì‘ë‹µ ë°˜í™˜

[í”„ë¡œì íŠ¸ êµ¬ì¡°]
- data_loaders: CSV/JSON íŒŒì¼ ë¡œë”© ëª¨ë“ˆ
- documents: ë¬¸ì„œ ë³€í™˜ ëª¨ë“ˆ (DataFrame â†’ LangChain Documents)
- embedding_and_vectordb: ì„ë² ë”© ìƒì„± ë° ChromaDB ì´ˆê¸°í™” ëª¨ë“ˆ
"""
import sys
from pathlib import Path
from typing import List, Dict, Optional
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request, Body
from fastapi.responses import FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import requests
from dotenv import load_dotenv

# -----------------------------------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ê²½ë¡œ ì„¤ì •
# -----------------------------------------------------------------------------

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ importê°€ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (API Key ë“±)
load_dotenv()

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
# data_loaders: ë°ì´í„° íŒŒì¼(csv, json) ë¡œë”© ìœ í‹¸ë¦¬í‹°
# documents: ë¬¸ì„œ ë³€í™˜ ìœ í‹¸ë¦¬í‹°
# embedding_and_vectordb: ë²¡í„° DB ìƒì„± ë° ê´€ë¦¬
from data_loaders import load_shelter_csv, load_all_disaster_jsons
from documents import csv_to_documents, json_to_documents
from embedding_and_vectordb import create_embeddings_and_vectordb
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import pandas as pd
import json
import re

# LangGraph ê´€ë ¨ import
from langchain_community.retrievers import BM25Retriever
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from typing import TypedDict, Annotated

# Simple EnsembleRetriever implementation
class EnsembleRetriever:
    """ê°„ë‹¨í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ êµ¬í˜„"""
    def __init__(self, retrievers, weights=None):
        self.retrievers = retrievers
        self.weights = weights or [1.0 / len(retrievers)] * len(retrievers)
    
    def invoke(self, query):
        all_docs = []
        for retriever, weight in zip(self.retrievers, self.weights):
            try:
                docs = retriever.invoke(query)
                for doc in docs:
                    doc.metadata['retriever_weight'] = weight
                    all_docs.append(doc)
            except:
                continue
        # ì¤‘ë³µ ì œê±° ë° ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì •ë ¬
        seen = set()
        unique_docs = []
        for doc in all_docs:
            doc_id = doc.page_content[:100]
            if doc_id not in seen:
                seen.add(doc_id)
                unique_docs.append(doc)
        return unique_docs[:10]

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
except (ImportError, Exception) as e:
    print(f"[WARNING] OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    OPENAI_AVAILABLE = False
    openai_client = None

# -----------------------------------------------------------------------------
# 2. Pydantic ëª¨ë¸ ì •ì˜ (Request/Response ìŠ¤í‚¤ë§ˆ)
# -----------------------------------------------------------------------------

class LocationExtractRequest(BaseModel):
    query: str

class LocationExtractResponse(BaseModel):
    success: bool
    location: Optional[str] = None
    coordinates: Optional[tuple] = None
    shelters: List[Dict] = []
    total_count: int = 0
    message: str = ""

class ChatbotRequest(BaseModel):
    message: str
    session_id: Optional[str] = "default"

class ChatbotResponse(BaseModel):
    response: str
    session_id: str


# -----------------------------------------------------------------------------
# 2-1. ì˜ë„ ë¶„ë¥˜ í•¨ìˆ˜ (find_location.pyì˜ llm_intent_classifier ì°¸ì¡°)
# -----------------------------------------------------------------------------

def classify_user_intent(query: str) -> str:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Returns:
        "find_shelter": ëŒ€í”¼ì†Œ ì°¾ê¸° ì˜ë„
        "disaster_guide": ì¬ë‚œí–‰ë™ìš”ë ¹ ì§ˆë¬¸
        "general_chat": ì¼ë°˜ ëŒ€í™”
    """
    # 1ì°¨: ëª…í™•í•œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë°”ë¡œ ë¶„ë¥˜ (ë¹ ë¥¸ ê²½ë¡œ)
    if "ëŒ€í”¼ì†Œ" in query or "í”¼ë‚œ" in query or "í”¼ë‚œì²˜" in query:
        print(f"  [ì˜ë„ë¶„ë¥˜] ëŒ€í”¼ì†Œ í‚¤ì›Œë“œ ë°œê²¬ -> find_shelter")
        return "find_shelter"
    
    if not OPENAI_AVAILABLE or not openai_client:
        print("  [ì˜ë„ë¶„ë¥˜] OpenAI ì‚¬ìš© ë¶ˆê°€ - í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ë¡œ ëŒ€ì²´")
        return keyword_intent_classifier(query)
    
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸ì„ ì„¸ ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. **ëŒ€í”¼ì†Œ ì°¾ê¸° (find_shelter)**:
   - ëŒ€í”¼ì†Œ, í”¼ë‚œì²˜, ì•ˆì „í•œ ì¥ì†Œë¥¼ ì°¾ëŠ” ì§ˆë¬¸
   - **ì§€ì—­ëª…, ì¥ì†Œëª…, ê±´ë¬¼ëª…, ëœë“œë§ˆí¬ë§Œ ì…ë ¥ëœ ê²½ìš° (ë§¤ìš° ì¤‘ìš”!)**
   - ì£¼ì†Œ, ë™ë„¤, êµ¬, ì‹œ, ì—­, ê±´ë¬¼ ë“±ì˜ ìœ„ì¹˜ ì •ë³´
   - ì˜ˆ: "ê°•ë‚¨ì—­ ëŒ€í”¼ì†Œ", "ì„œìš¸ì—­", "ë§ˆí¬êµ¬", "ì ì‹¤ ë¡¯ë°ì›”ë“œ", "ëª…ë™", "ì—¬ì˜ë„", "ê·¼ì²˜ í”¼ë‚œì²˜"

2. **ì¬ë‚œí–‰ë™ìš”ë ¹ (disaster_guide)**:
   - ì¬ë‚œ ìƒí™© ëŒ€ì²˜ ë°©ë²•ì„ ë¬»ëŠ” ì§ˆë¬¸
   - í–‰ë™ ìš”ë ¹, ëŒ€í”¼ ë°©ë²•, ì•ˆì „ ìˆ˜ì¹™ ë¬¸ì˜
   - "ì–´ë–»ê²Œ", "ë°©ë²•", "ëŒ€ì²˜", "í–‰ë™ìš”ë ¹" ë“±ì˜ ì˜ë¬¸ë¬¸
   - ì˜ˆ: "ì§€ì§„ ë‚¬ì„ ë•Œ ì–´ë–»ê²Œ í•´?", "í™”ì¬ ë°œìƒì‹œ í–‰ë™ìš”ë ¹", "íƒœí’ ëŒ€ë¹„ë²•"

3. **ì¼ë°˜ ëŒ€í™” (general_chat)**:
   - ì¸ì‚¬, ë„ì›€ë§, ì‚¬ìš©ë²• ë¬¸ì˜
   - ëŒ€í”¼ì†Œë‚˜ ì¬ë‚œê³¼ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸
   - ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”", "ë„ì›€ë§", "ì‚¬ìš©ë²•"

**ì¤‘ìš”**: ì§€ì—­ëª…ì´ë‚˜ ì¥ì†Œëª…ë§Œ ì–¸ê¸‰ë˜ë©´ ë¬´ì¡°ê±´ find_shelterë¡œ ë¶„ë¥˜í•˜ì„¸ìš”!

ì‘ë‹µ í˜•ì‹ (JSON):
{"intent": "find_shelter" ë˜ëŠ” "disaster_guide" ë˜ëŠ” "general_chat", "confidence": 0.0~1.0, "reason": "íŒë‹¨ ì´ìœ "}"""
                },
                {
                    "role": "user",
                    "content": query
                }
            ],
            temperature=0,
            max_tokens=150,
            response_format={"type": "json_object"}
        )
        
        result = json.loads(response.choices[0].message.content)
        intent = result.get("intent", "general_chat")
        confidence = result.get("confidence", 0.0)
        reason = result.get("reason", "")
        
        print(f"  [ì˜ë„ë¶„ë¥˜] LLM ê²°ê³¼: {intent} (ì‹ ë¢°ë„: {confidence}, ì´ìœ : {reason})")
        
        # ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¬í™•ì¸
        if confidence < 0.6:
            print(f"  [ì˜ë„ë¶„ë¥˜] ì‹ ë¢°ë„ ë‚®ìŒ({confidence}) - í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¬í™•ì¸")
            return keyword_intent_classifier(query)
        
        return intent
        
    except Exception as e:
        print(f"  [ì˜ë„ë¶„ë¥˜] LLM ì˜¤ë¥˜: {e} - í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´")
        return keyword_intent_classifier(query)


def keyword_intent_classifier(query: str) -> str:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ (LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ í´ë°±)
    """
    print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ì¿¼ë¦¬ ë¶„ì„: '{query}'")
    
    # ëŒ€í”¼ì†Œ ê´€ë ¨ í‚¤ì›Œë“œ
    shelter_keywords = ["ëŒ€í”¼ì†Œ", "ëŒ€í”¼", "í”¼ë‚œ", "í”¼ë‚œì²˜", "ì•ˆì „í•œ ê³³", "ìˆ¨ì„ ê³³", "ë¹„ìƒëŒ€í”¼", "ê·¼ì²˜", "ì£¼ë³€"]
    
    # ì¬ë‚œí–‰ë™ìš”ë ¹ ê´€ë ¨ í‚¤ì›Œë“œ
    disaster_keywords = [
        "ì§€ì§„", "í™”ì¬", "íƒœí’", "í™ìˆ˜", "ì‚°ì‚¬íƒœ", "í­í’", "í•´ì¼", "ì“°ë‚˜ë¯¸", "tsunami",
        "í–‰ë™ìš”ë ¹", "ëŒ€ì²˜ë²•", "ëŒ€ì²˜ë°©ë²•", "ëŒ€ë¹„", "ì•ˆì „ìˆ˜ì¹™", "ì–´ë–»ê²Œ", "ë°©ë²•", "í•´ì•¼",
        "í™”ì‚°", "ë°©ì‚¬ëŠ¥", "ê°€ìŠ¤", "ëŒ", "ì‚°ë¶ˆ", "í­ë°œ", "ë¶„í™”", "ë‚™ë¢°",
        "ë°œìƒ", "ë‚¬ì„", "ì¼ì–´ë‚˜", "ìƒê¸°ë©´", "ê²½ìš°"
    ]
    
    # í•œêµ­ ì§€ì—­ëª… íŒ¨í„´
    location_pattern = r'(êµ¬|ë™|ì—­|ì‹œ|ì|ë©´|ë¦¬|ë¡œ|ê¸¸|ëŒ€ë¡œ)'
    
    # ì¼ë°˜ ëŒ€í™” í‚¤ì›Œë“œ
    general_keywords = ["ì•ˆë…•", "ë„ì›€ë§", "ì‚¬ìš©ë²•", "ì„¤ëª…", "ë­ì•¼", "ë‚ ì”¨", "ê³ ë§ˆì›Œ", "ê°ì‚¬"]
    
    # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ì¶”ì 
    matched_shelter = [k for k in shelter_keywords if k in query]
    matched_disaster = [k for k in disaster_keywords if k in query]
    matched_general = [k for k in general_keywords if k in query]
    
    print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ëŒ€í”¼ì†Œ í‚¤ì›Œë“œ: {matched_shelter}")
    print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ì¬ë‚œ í‚¤ì›Œë“œ: {matched_disaster}")
    print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ì¼ë°˜ í‚¤ì›Œë“œ: {matched_general}")
    
    # 1. ì¼ë°˜ ëŒ€í™” ë¨¼ì € í™•ì¸
    if matched_general and not (matched_shelter or matched_disaster):
        print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ê²°ê³¼: general_chat")
        return "general_chat"
    
    # 2. ì¬ë‚œí–‰ë™ìš”ë ¹ í™•ì¸
    if matched_disaster:
        # ë‹¨, ëŒ€í”¼ì†Œ í‚¤ì›Œë“œë„ í•¨ê»˜ ìˆìœ¼ë©´ ëŒ€í”¼ì†Œ ê²€ìƒ‰ìœ¼ë¡œ ê°„ì£¼
        if matched_shelter:
            print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ê²°ê³¼: find_shelter (ì¬ë‚œ+ëŒ€í”¼ì†Œ)")
            return "find_shelter"
        print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ê²°ê³¼: disaster_guide")
        return "disaster_guide"
    
    # 3. ëŒ€í”¼ì†Œ ê²€ìƒ‰ í™•ì¸
    if matched_shelter or re.search(location_pattern, query):
        print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ê²°ê³¼: find_shelter")
        return "find_shelter"
    
    # 4. ì§§ì€ ì§ˆë¬¸ì€ ëŒ€í”¼ì†Œ ê²€ìƒ‰ìœ¼ë¡œ ê°„ì£¼ (ì§€ì—­ëª…ì¼ ê°€ëŠ¥ì„±)
    if len(query.strip()) <= 5:
        print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ê²°ê³¼: find_shelter (ì§§ì€ ì¿¼ë¦¬)")
        return "find_shelter"
    
    # 5. ê¸°ë³¸ê°’ì€ ì¼ë°˜ ëŒ€í™”
    print(f"  [í‚¤ì›Œë“œë¶„ë¥˜] ê²°ê³¼: general_chat (ê¸°ë³¸ê°’)")
    return "general_chat"


# -----------------------------------------------------------------------------
# 2-2. LangGraph í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë° Agent ìƒì„± í•¨ìˆ˜
# -----------------------------------------------------------------------------

def create_hybrid_retrievers():
    """í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± (Vector + BM25)"""
    if vectorstore is None:
        return None, None
    
    try:
        # 1. Vector Retriever
        shelter_vector_retriever = vectorstore.as_retriever(
            search_kwargs={"k": 5, "filter": {"type": "shelter"}}
        )
        guideline_vector_retriever = vectorstore.as_retriever(
            search_kwargs={"k": 3, "filter": {"type": "disaster_guideline"}}
        )
        
        # 2. BM25 Retriever ìƒì„±
        def create_bm25_retriever(doc_type: str):
            try:
                all_docs = vectorstore.get(where={"type": doc_type})
                if not all_docs or 'documents' not in all_docs:
                    return None
                
                documents = []
                for i, text in enumerate(all_docs['documents']):
                    metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
                    documents.append(Document(page_content=text, metadata=metadata))
                
                bm25_retriever = BM25Retriever.from_documents(documents)
                bm25_retriever.k = 5
                return bm25_retriever
            except Exception as e:
                print(f"âš ï¸ BM25 Retriever ìƒì„± ì‹¤íŒ¨ ({doc_type}): {e}")
                return None
        
        shelter_bm25 = create_bm25_retriever("shelter")
        guideline_bm25 = create_bm25_retriever("disaster_guideline")
        
        # 3. Ensemble (Hybrid) Retriever
        shelter_hybrid = EnsembleRetriever(
            retrievers=[shelter_vector_retriever, shelter_bm25] if shelter_bm25 else [shelter_vector_retriever],
            weights=[0.6, 0.4] if shelter_bm25 else [1.0]
        )
        
        guideline_hybrid = EnsembleRetriever(
            retrievers=[guideline_vector_retriever, guideline_bm25] if guideline_bm25 else [guideline_vector_retriever],
            weights=[0.7, 0.3] if guideline_bm25 else [1.0]
        )
        
        return shelter_hybrid, guideline_hybrid
        
    except Exception as e:
        print(f"âš ï¸ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None


def create_langgraph_app():
    """LangGraph Agent ìƒì„±"""
    
    # 1. LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    llm_creative = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)  # ì¼ë°˜ ì§€ì‹ìš©
    
    # 2. ì˜ë„ ë¶„ë¥˜ ì²´ì¸
    intent_classification_prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì§ˆë¬¸ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. **shelter_search**: íŠ¹ì • ìœ„ì¹˜ì˜ ëŒ€í”¼ì†Œ ì°¾ê¸°
   - ì˜ˆ: "í•œë¼ì‚° ê·¼ì²˜ ëŒ€í”¼ì†Œ", "ê°•ë‚¨ì—­ ëŒ€í”¼ì†Œ", "ë™ëŒ€ë¬¸ë§¨ì…˜ ëŒ€í”¼ì†Œ ì •ë³´"
   
2. **shelter_count**: íŠ¹ì • ì¡°ê±´ì˜ ëŒ€í”¼ì†Œ ê°œìˆ˜ ì„¸ê¸°
   - ì˜ˆ: "ì„œìš¸ ëŒ€í”¼ì†Œ ê°œìˆ˜", "ì§€í•˜ ëŒ€í”¼ì†Œ ëª‡ ê°œ", "ë¶€ì‚° ë¯¼ë°©ìœ„ ëŒ€í”¼ì†ŒëŠ” ì´ ëª‡ ê°œ"
   
3. **shelter_capacity**: ìˆ˜ìš©ì¸ì› ê¸°ì¤€ ëŒ€í”¼ì†Œ ì°¾ê¸°
   - ì˜ˆ: "ì²œ ëª… ì´ìƒ ìˆ˜ìš© ê°€ëŠ¥í•œ ëŒ€í”¼ì†Œ", "100ëª… ìˆ˜ìš© ê°€ëŠ¥í•œ ê·¼ì²˜ ëŒ€í”¼ì†Œ"
   
4. **disaster_guideline**: ì¬ë‚œ í–‰ë™ìš”ë ¹ ì§ˆë¬¸
   - ì˜ˆ: "ì§€ì§„ ë°œìƒ ì‹œ í–‰ë™ìš”ë ¹", "í™”ì¬ ëŒ€ì²˜ë²•", "ì‚°ì‚¬íƒœ ë‚¬ì„ ë•Œ"
   
5. **hybrid_location_disaster**: ìœ„ì¹˜ + ì¬ë‚œ ìƒí™© ë³µí•© ì§ˆë¬¸
   - ì˜ˆ: "ì„¤ì•…ì‚° ê·¼ì²˜ì¸ë° ì‚°ì‚¬íƒœ ë°œìƒ ì‹œ", "ê°•ë‚¨ì—­ì—ì„œ ì§€ì§„ ë‚˜ë©´"
   
6. **general_knowledge**: ì¬ë‚œ ê´€ë ¨ ì¼ë°˜ ì§€ì‹ (ì •ì˜, ì›ì¸ ë“±)
   - ì˜ˆ: "ì§€ì§„ì´ ë­ì•¼", "ì“°ë‚˜ë¯¸ë€", "íƒœí’ì˜ ì›ì¸"
   
7. **general_chat**: ì¼ë°˜ ëŒ€í™”
   - ì˜ˆ: "ì•ˆë…•", "ê³ ë§ˆì›Œ", "ë‚ ì”¨ ì–´ë•Œ"

**ì‘ë‹µ í˜•ì‹**: JSON
{{
    "intent": "ì¹´í…Œê³ ë¦¬ëª…",
    "confidence": 0.95,
    "reason": "ë¶„ë¥˜ ê·¼ê±°"
}}"""),
        ("user", "{query}")
    ])
    
    intent_chain = intent_classification_prompt | llm | StrOutputParser()
    
    # 3. ì§ˆë¬¸ ì¬ì •ì˜ ì²´ì¸ (ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ)
    query_rewrite_prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”.

**ì¬ì‘ì„± ê·œì¹™**:
1. í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (ë¶ˆí•„ìš”í•œ ì¡°ì‚¬, ì–´ë¯¸ ì œê±°)
2. ë™ì˜ì–´ ì¶”ê°€ (ì˜ˆ: "ëŒ€í”¼ì†Œ" â†’ "ëŒ€í”¼ì†Œ í”¼ë‚œì²˜")
3. ì§€ì—­ëª…ì€ ë‹¤ì–‘í•œ í˜•íƒœë¡œ í‘œí˜„ (ì˜ˆ: "ì„œìš¸" â†’ "ì„œìš¸ ì„œìš¸ì‹œ ì„œìš¸íŠ¹ë³„ì‹œ")
4. ìœ„ì¹˜ ìœ í˜• ëª…í™•í™” (ì˜ˆ: "ì§€í•˜" â†’ "ì§€í•˜ ì§€í•˜ì¸µ")
5. ìµœëŒ€ 10ë‹¨ì–´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ

**ì˜ˆì‹œ**:
- "í•œë¼ì‚° ê·¼ì²˜ ëŒ€í”¼ì†ŒëŠ”?" â†’ "í•œë¼ì‚° ì œì£¼ ëŒ€í”¼ì†Œ í”¼ë‚œì²˜"
- "ì„œìš¸ì— ìˆëŠ” ì§€í•˜ ëŒ€í”¼ì†Œ" â†’ "ì„œìš¸ ì„œìš¸ì‹œ ì§€í•˜ ì§€í•˜ì¸µ ëŒ€í”¼ì†Œ"
- "ë™ëŒ€ë¬¸ë§¨ì…˜ ëŒ€í”¼ì†Œ" â†’ "ë™ëŒ€ë¬¸ë§¨ì…˜ ë™ëŒ€ë¬¸ ëŒ€í”¼ì†Œ"

**ì‘ë‹µ**: ì¬ì‘ì„±ëœ ì¿¼ë¦¬ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)"""),
        ("user", "{original_query}")
    ])
    
    query_rewrite_chain = query_rewrite_prompt | llm | StrOutputParser()
    
    # 4. í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±
    shelter_hybrid, guideline_hybrid = create_hybrid_retrievers()
    
    # 5. Tools ì •ì˜
    @tool
    def search_shelter_by_location(query: str) -> str:
        """
        íŠ¹ì • ìœ„ì¹˜ì˜ ëŒ€í”¼ì†Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        ì¹´ì¹´ì˜¤ APIë¡œ ì¢Œí‘œë¥¼ ì°¾ê³ , ê°€ì¥ ê°€ê¹Œìš´ ëŒ€í”¼ì†Œ 5ê³³ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            query: ìœ„ì¹˜ ì •ë³´ (ì§€ëª…, ê±´ë¬¼ëª…, ì£¼ì†Œ ë“±)
        """
        try:
            # ì¿¼ë¦¬ ì¬ì •ì˜
            rewritten = query_rewrite_chain.invoke({"original_query": query})
            print(f"[search_shelter_by_location] ì¬ì •ì˜: {query} â†’ {rewritten}")
            
            # ì¹´ì¹´ì˜¤ APIë¡œ ì¢Œí‘œ ê²€ìƒ‰
            kakao_api_key = os.getenv("KAKAO_REST_API_KEY")
            if not kakao_api_key:
                return "ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            headers = {"Authorization": f"KakaoAK {kakao_api_key}"}
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            params = {"query": rewritten}
            
            response = requests.get(url, headers=headers, params=params)
            data = response.json()
            
            if not data.get("documents"):
                return f"'{query}' ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ì¢Œí‘œ
            place = data["documents"][0]
            user_lat = float(place["y"])
            user_lon = float(place["x"])
            place_name = place["place_name"]
            
            print(f"[search_shelter_by_location] ì¢Œí‘œ: {place_name} ({user_lat}, {user_lon})")
            
            # Haversine ê±°ë¦¬ ê³„ì‚°
            def haversine(lat1, lon1, lat2, lon2):
                from math import radians, sin, cos, sqrt, atan2
                R = 6371
                dlat = radians(lat2 - lat1)
                dlon = radians(lon2 - lon1)
                a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2
                c = 2 * atan2(sqrt(a), sqrt(1-a))
                return R * c
            
            # ëª¨ë“  ëŒ€í”¼ì†Œ ê°€ì ¸ì˜¤ê¸°
            all_data = vectorstore.get(where={"type": "shelter"})
            shelters = []
            
            for i, metadata in enumerate(all_data['metadatas']):
                try:
                    lat = float(metadata.get('latitude', 0))
                    lon = float(metadata.get('longitude', 0))
                    if lat == 0 or lon == 0:
                        continue
                    
                    distance = haversine(user_lat, user_lon, lat, lon)
                    shelters.append({
                        'name': metadata.get('facility_name', 'N/A'),
                        'address': metadata.get('address', 'N/A'),
                        'distance': distance,
                        'capacity': int(metadata.get('capacity', 0)),
                        'shelter_type': metadata.get('shelter_type', 'N/A'),
                        'facility_type': metadata.get('facility_type', 'N/A')
                    })
                except Exception as e:
                    continue
            
            # ê±°ë¦¬ìˆœ ì •ë ¬
            shelters.sort(key=lambda x: x['distance'])
            top_5 = shelters[:5]
            
            if not top_5:
                return f"'{place_name}' ê·¼ì²˜ì— ëŒ€í”¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ê²°ê³¼ í¬ë§·íŒ…
            result = f"ğŸ“ **{place_name}** ê·¼ì²˜ ëŒ€í”¼ì†Œ {len(top_5)}ê³³\n\n"
            for i, s in enumerate(top_5, 1):
                result += f"{i}. **{s['name']}**\n"
                result += f"   ğŸ“ ê±°ë¦¬: {s['distance']:.2f}km\n"
                result += f"   ğŸ“ ì£¼ì†Œ: {s['address']}\n"
                result += f"   ğŸ“ ìœ„ì¹˜: {s['shelter_type']}\n"
                result += f"   ğŸ“ ìˆ˜ìš©ì¸ì›: {s['capacity']:,}ëª…\n\n"
            
            return result.strip()
            
        except Exception as e:
            print(f"[ERROR] search_shelter_by_location: {e}")
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    @tool
    def count_shelters(query: str) -> str:
        """
        íŠ¹ì • ì¡°ê±´(ì§€ì—­, ìœ„ì¹˜ìœ í˜• ë“±)ì— ë§ëŠ” ëŒ€í”¼ì†Œ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ ì¡°ê±´ (ì˜ˆ: "ì„œìš¸ ì§€í•˜", "ë¶€ì‚° ë¯¼ë°©ìœ„")
        """
        try:
            # ì¿¼ë¦¬ ì¬ì •ì˜
            rewritten = query_rewrite_chain.invoke({"original_query": query})
            print(f"[count_shelters] ì¬ì •ì˜: {query} â†’ {rewritten}")
            
            if shelter_hybrid is None:
                return "ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            results = shelter_hybrid.invoke(rewritten)
            
            # ì¤‘ë³µ ì œê±°
            seen = set()
            count = 0
            for doc in results:
                name = doc.metadata.get('facility_name', '')
                if name and name not in seen:
                    seen.add(name)
                    count += 1
            
            if count == 0:
                return f"'{query}' ì¡°ê±´ì— ë§ëŠ” ëŒ€í”¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return f"**'{query}'** ì¡°ê±´ì— ë§ëŠ” ëŒ€í”¼ì†ŒëŠ” ì´ **{count}ê°œ**ì…ë‹ˆë‹¤."
            
        except Exception as e:
            print(f"[ERROR] count_shelters: {e}")
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    @tool
    def search_shelter_by_capacity(query: str) -> str:
        """
        ìˆ˜ìš©ì¸ì› ê¸°ì¤€ìœ¼ë¡œ ëŒ€í”¼ì†Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ìˆ˜ìš©ì¸ì› ì¡°ê±´ (ì˜ˆ: "ì²œ ëª… ì´ìƒ", "100ëª… ìˆ˜ìš© ê°€ëŠ¥")
        """
        try:
            # ìˆ«ì ì¶”ì¶œ
            import re
            numbers = re.findall(r'\d+', query)
            if not numbers:
                return "ìˆ˜ìš©ì¸ì›ì„ ëª…í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 1000ëª… ì´ìƒ)"
            
            min_capacity = int(numbers[0])
            
            # ìˆ«ì ë‹¨ìœ„ ì²˜ë¦¬ (ì²œ, ë§Œ)
            if 'ì²œ' in query:
                min_capacity *= 1000
            elif 'ë§Œ' in query:
                min_capacity *= 10000
            
            print(f"[search_shelter_by_capacity] ìµœì†Œ ìˆ˜ìš©ì¸ì›: {min_capacity}ëª…")
            
            # ëª¨ë“  ëŒ€í”¼ì†Œ ê°€ì ¸ì˜¤ê¸°
            all_data = vectorstore.get(where={"type": "shelter"})
            shelters = []
            
            for metadata in all_data['metadatas']:
                capacity = int(metadata.get('capacity', 0))
                if capacity >= min_capacity:
                    shelters.append({
                        'name': metadata.get('facility_name', 'N/A'),
                        'address': metadata.get('address', 'N/A'),
                        'capacity': capacity,
                        'shelter_type': metadata.get('shelter_type', 'N/A')
                    })
            
            # ìˆ˜ìš©ì¸ì› ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            shelters.sort(key=lambda x: x['capacity'], reverse=True)
            top_10 = shelters[:10]
            
            if not top_10:
                return f"{min_capacity:,}ëª… ì´ìƒ ìˆ˜ìš© ê°€ëŠ¥í•œ ëŒ€í”¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            result = f"ğŸ“Š **{min_capacity:,}ëª… ì´ìƒ** ìˆ˜ìš© ê°€ëŠ¥í•œ ëŒ€í”¼ì†Œ **{len(shelters)}ê³³** ì¤‘ ìƒìœ„ 10ê³³\n\n"
            for i, s in enumerate(top_10, 1):
                result += f"{i}. **{s['name']}** ({s['capacity']:,}ëª…)\n"
                result += f"   ğŸ“ {s['address']}\n"
                result += f"   ğŸ“ ìœ„ì¹˜: {s['shelter_type']}\n\n"
            
            return result.strip()
            
        except Exception as e:
            print(f"[ERROR] search_shelter_by_capacity: {e}")
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    @tool
    def search_disaster_guideline(query: str) -> str:
        """
        ì¬ë‚œ í–‰ë™ìš”ë ¹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ì¬ë‚œ ìœ í˜• (ì˜ˆ: "ì§€ì§„", "í™”ì¬", "ì‚°ì‚¬íƒœ")
        """
        try:
            # ì¿¼ë¦¬ ì¬ì •ì˜
            rewritten = query_rewrite_chain.invoke({"original_query": query})
            print(f"[search_disaster_guideline] ì¬ì •ì˜: {query} â†’ {rewritten}")
            
            if guideline_hybrid is None:
                return "ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
            results = guideline_hybrid.invoke(rewritten)
            
            if not results:
                return f"'{query}' ê´€ë ¨ í–‰ë™ìš”ë ¹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ìƒìœ„ 3ê°œ ê²°ê³¼ í†µí•©
            combined = "\n\n".join([doc.page_content for doc in results[:3]])
            
            return f"ğŸš¨ **{query} í–‰ë™ìš”ë ¹**\n\n{combined}"
            
        except Exception as e:
            print(f"[ERROR] search_disaster_guideline: {e}")
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    @tool
    def answer_general_knowledge(query: str) -> str:
        """
        ì¬ë‚œ ê´€ë ¨ ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤. (ì •ì˜, ì›ì¸, íŠ¹ì§• ë“±)
        VectorDBì— ì—†ëŠ” ì •ë³´ëŠ” LLMì˜ ì‚¬ì „ í•™ìŠµ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤.
        
        Args:
            query: ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ (ì˜ˆ: "ì§€ì§„ì´ ë­ì•¼", "ì“°ë‚˜ë¯¸ë€")
        """
        try:
            print(f"[answer_general_knowledge] ì§ˆë¬¸: {query}")
            
            # LLMì—ê²Œ ì§ì ‘ ì§ˆë¬¸ (ì‚¬ì „ í•™ìŠµ ì§€ì‹ í™œìš©)
            prompt = f"""ë‹¹ì‹ ì€ ì¬ë‚œ ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ë‹µë³€ í˜•ì‹:
- í•µì‹¬ ì •ì˜ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…
- ì£¼ìš” íŠ¹ì§•ì´ë‚˜ ì›ì¸ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ì •ë¦¬
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…
- ìµœëŒ€ 200ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ"""
            
            response = llm_creative.invoke([HumanMessage(content=prompt)])
            
            return f"ğŸ’¡ **{query}**\n\n{response.content}"
            
        except Exception as e:
            print(f"[ERROR] answer_general_knowledge: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    # 6. Tools ë¦¬ìŠ¤íŠ¸
    tools = [
        search_shelter_by_location,
        count_shelters,
        search_shelter_by_capacity,
        search_disaster_guideline,
        answer_general_knowledge
    ]
    
    # 7. LLMì— Tools ë°”ì¸ë”©
    llm_with_tools = llm.bind_tools(tools)
    
    # 8. State ì •ì˜
    class AgentState(TypedDict):
        messages: Annotated[list[BaseMessage], add_messages]
        intent: str
        rewritten_query: str
    
    # 9. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ì¬ë‚œ ì•ˆì „ ì „ë¬¸ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™**:
1. **ì •í™•ì„± ìš°ì„ **: ì œê³µëœ ë„êµ¬ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ê³ , ì—†ëŠ” ì •ë³´ëŠ” ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”
2. **ì˜ë„ íŒŒì•…**: ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì •í™•íˆ ë¶„ë¥˜í•˜ê³  ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”
3. **ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬**: ì—¬ëŸ¬ ì˜ë„ê°€ ì„ì¸ ì§ˆë¬¸ì€ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”

**ë„êµ¬ ì„ íƒ ê°€ì´ë“œ**:
- íŠ¹ì • ìœ„ì¹˜ ëŒ€í”¼ì†Œ ì°¾ê¸° â†’ **search_shelter_by_location**
- ëŒ€í”¼ì†Œ ê°œìˆ˜ ì„¸ê¸° â†’ **count_shelters**
- ìˆ˜ìš©ì¸ì› ê¸°ì¤€ ê²€ìƒ‰ â†’ **search_shelter_by_capacity**
- ì¬ë‚œ í–‰ë™ìš”ë ¹ â†’ **search_disaster_guideline**
- ì¬ë‚œ ê´€ë ¨ ì¼ë°˜ ì§€ì‹ (ì •ì˜, ì›ì¸) â†’ **answer_general_knowledge**

**ë³µí•© ì§ˆë¬¸ ì˜ˆì‹œ**:
"ì„¤ì•…ì‚° ê·¼ì²˜ì¸ë° ì‚°ì‚¬íƒœ ë°œìƒ ì‹œ ì–´ë–»ê²Œ í•´ì•¼ í•´?"
â†’ 1ë‹¨ê³„: search_shelter_by_location("ì„¤ì•…ì‚°")
â†’ 2ë‹¨ê³„: search_disaster_guideline("ì‚°ì‚¬íƒœ")
â†’ 3ë‹¨ê³„: ë‘ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©

**ì‘ë‹µ í˜•ì‹**:
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì •ë³´ ì œê³µ
- ì¤‘ìš” ì •ë³´ëŠ” **ë³¼ë“œì²´** ê°•ì¡°
- ìˆ«ìëŠ” ì‰¼í‘œ êµ¬ë¶„ (1,000ëª…)
- ì´ëª¨ì§€ ì ì ˆíˆ í™œìš© (ğŸ“ğŸš¨ğŸ’¡ğŸ“Š)
"""
    
    # 10. ë…¸ë“œ í•¨ìˆ˜ë“¤
    def intent_classifier_node(state: AgentState):
        """ì˜ë„ ë¶„ë¥˜ ë…¸ë“œ"""
        messages = state["messages"]
        last_message = messages[-1].content
        
        print(f"\n[ì˜ë„ë¶„ë¥˜ ë…¸ë“œ] ì…ë ¥: {last_message}")
        
        try:
            # ì˜ë„ ë¶„ë¥˜
            intent_result = intent_chain.invoke({"query": last_message})
            import json
            intent_data = json.loads(intent_result)
            intent = intent_data["intent"]
            
            print(f"[ì˜ë„ë¶„ë¥˜ ë…¸ë“œ] ê²°ê³¼: {intent} (ì‹ ë¢°ë„: {intent_data.get('confidence', 0)})")
            
            return {"intent": intent}
            
        except Exception as e:
            print(f"[ì˜ë„ë¶„ë¥˜ ë…¸ë“œ] ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return {"intent": "general_chat"}
    
    def query_rewrite_node(state: AgentState):
        """ì§ˆë¬¸ ì¬ì •ì˜ ë…¸ë“œ"""
        messages = state["messages"]
        last_message = messages[-1].content
        intent = state.get("intent", "")
        
        # ì¼ë°˜ ëŒ€í™”ë‚˜ ì¼ë°˜ ì§€ì‹ì€ ì¬ì •ì˜ ë¶ˆí•„ìš”
        if intent in ["general_chat", "general_knowledge"]:
            return {"rewritten_query": last_message}
        
        print(f"\n[ì§ˆë¬¸ì¬ì •ì˜ ë…¸ë“œ] ì…ë ¥: {last_message}")
        
        try:
            rewritten = query_rewrite_chain.invoke({"original_query": last_message})
            print(f"[ì§ˆë¬¸ì¬ì •ì˜ ë…¸ë“œ] ê²°ê³¼: {rewritten}")
            return {"rewritten_query": rewritten}
        except Exception as e:
            print(f"[ì§ˆë¬¸ì¬ì •ì˜ ë…¸ë“œ] ì˜¤ë¥˜: {e}")
            return {"rewritten_query": last_message}
    
    def agent_node(state: AgentState):
        """ì—ì´ì „íŠ¸ ì¶”ë¡  ë…¸ë“œ (ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰)"""
        messages = state["messages"]
        intent = state.get("intent", "")
        
        print(f"\n[ì—ì´ì „íŠ¸ ë…¸ë“œ] ì˜ë„: {intent}")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        if not any(isinstance(m, SystemMessage) for m in messages):
            messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages
        
        # LLM í˜¸ì¶œ (ë„êµ¬ ì„ íƒ)
        response = llm_with_tools.invoke(messages)
        
        return {"messages": [response]}
    
    def should_continue(state: AgentState):
        """ë„êµ¬ ì‹¤í–‰ í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        messages = state["messages"]
        last_message = messages[-1]
        
        # ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ ë„êµ¬ ì‹¤í–‰
        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            return "tools"
        
        # ì—†ìœ¼ë©´ ì¢…ë£Œ
        return END
    
    # 11. ê·¸ë˜í”„ êµ¬ì„±
    workflow = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("intent_classifier", intent_classifier_node)
    workflow.add_node("query_rewrite", query_rewrite_node)
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", ToolNode(tools))
    
    # ì—£ì§€ ì—°ê²°
    workflow.add_edge(START, "intent_classifier")
    workflow.add_edge("intent_classifier", "query_rewrite")
    workflow.add_edge("query_rewrite", "agent")
    workflow.add_conditional_edges("agent", should_continue, ["tools", END])
    workflow.add_edge("tools", "agent")  # ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì—ì´ì „íŠ¸ë¡œ
    
    # 12. ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸íŠ¸
    memory = MemorySaver()
    
    # 13. ì»´íŒŒì¼
    app = workflow.compile(checkpointer=memory)
    
    print("[LangGraph] ì•± ìƒì„± ì™„ë£Œ")
    print(f"  - ë…¸ë“œ: intent_classifier â†’ query_rewrite â†’ agent â‡„ tools")
    print(f"  - ë„êµ¬: {len(tools)}ê°œ")
    
    return app


# -----------------------------------------------------------------------------
# 3. FastAPI Lifespan (ìˆ˜ëª… ì£¼ê¸°) í•¸ë“¤ëŸ¬
# -----------------------------------------------------------------------------

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ˆê¸°í™” ë° ì •ë¦¬ ì‘ì—…
    ì•± ì‹¤í–‰ ì‹œ:
    - Vector DB ë¡œë“œ ë° ì´ˆê¸°í™”
    - ëŒ€í”¼ì†Œ ë°ì´í„° ë¡œë“œ
    - LangGraph Agent ì´ˆê¸°í™”
    ì•± ì¢…ë£Œ ì‹œ:
    - ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (í˜„ì¬ëŠ” ë³„ë„ ì •ë¦¬ ì‘ì—… ì—†ìŒ)
    """
    global vectorstore, shelter_df, embeddings
    global shelter_hybrid_retriever, guideline_hybrid_retriever, langgraph_app
    
    # OpenAI ì„ë² ë”© ì´ˆê¸°í™”
    try:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=os.getenv("OPENAI_API_KEY"))
        print("[lifespan] ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        embeddings = None
        print(f"[lifespan] ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    # ë²¡í„° DB ë¡œë“œ ì‹œë„
    try:
        vectorstore = Chroma(
            collection_name="shelter_and_disaster_guidelines",
            embedding_function=embeddings,
            persist_directory="chroma_db"
        )
        print("[lifespan] ë²¡í„°DB ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        vectorstore = None
        print(f"[lifespan] ë²¡í„°DB ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ëŒ€í”¼ì†Œ ë°ì´í„° ë¡œë“œ
    try:
        shelter_data = load_shelter_csv("shelter.csv", data_dir="./data")
        shelter_df = pd.DataFrame(shelter_data)
        print(f"[lifespan] ëŒ€í”¼ì†Œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(shelter_df)}ê°œ")
    except Exception as e:
        shelter_df = None
        print(f"[lifespan] ëŒ€í”¼ì†Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë¦¬íŠ¸ë¦¬ë²„ ë° LangGraph ì´ˆê¸°í™”
    try:
        shelter_hybrid_retriever, guideline_hybrid_retriever = create_hybrid_retrievers()
        langgraph_app = create_langgraph_app()
        print("[lifespan] LangGraph Agent ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        shelter_hybrid_retriever = None
        guideline_hybrid_retriever = None
        langgraph_app = None
        print(f"[lifespan] LangGraph ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    yield # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘
    
    # ì—¬ê¸°ì— ì¢…ë£Œ ì‹œ í•„ìš”í•œ ì •ë¦¬ ì‘ì—… ì½”ë“œë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŒ

# FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° lifespan í•¸ë“¤ëŸ¬ ì—°ê²°
app = FastAPI(title="ëŒ€í”¼ì†Œ ì•ˆë‚´ ì±—ë´‡ API", lifespan=lifespan)

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
vectorstore = None
shelter_df = None
embeddings = None
shelter_hybrid_retriever = None
guideline_hybrid_retriever = None
langgraph_app = None




# -----------------------------------------------------------------------------
# 4. API ì—”ë“œí¬ì¸íŠ¸: ì§€ëª… ì¶”ì¶œ ë° í†µí•© ê²€ìƒ‰
# -----------------------------------------------------------------------------

@app.post("/api/location/extract")
async def extract_location(request: LocationExtractRequest = Body(...)):
    """
    ì‚¬ìš©ì ì§ˆì˜(Query)ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.
    
    =========================================================================
    [NEW] LangGraph Agent ê¸°ë°˜ í†µí•© ì²˜ë¦¬
    =========================================================================
    
    ê¸°ì¡´ ë°©ì‹ (ì˜ë„ ë¶„ë¥˜ â†’ ë¶„ê¸° ì²˜ë¦¬)ì—ì„œ Agent ìë™ ì²˜ë¦¬ë¡œ ë³€ê²½:
    
    1. **Agentê°€ ì§ˆë¬¸ ë¶„ì„**
       - ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ìë™ìœ¼ë¡œ íŒŒì•…
       - í•„ìš”í•œ ë„êµ¬ë¥¼ ìŠ¤ìŠ¤ë¡œ ì„ íƒí•˜ì—¬ ì‹¤í–‰
    
    2. **ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬**
       - search_shelter: ì§€ì—­ëª…/ê±´ë¬¼ëª…ìœ¼ë¡œ ëŒ€í”¼ì†Œ ê²€ìƒ‰ (í•˜ì´ë¸Œë¦¬ë“œ)
       - search_shelter_by_kakao: ì¹´ì¹´ì˜¤ API + ì¢Œí‘œ ê¸°ë°˜ ëŒ€í”¼ì†Œ ê²€ìƒ‰
       - search_guideline: ì¬ë‚œ í–‰ë™ìš”ë ¹ ê²€ìƒ‰
       - get_shelter_statistics: ëŒ€í”¼ì†Œ í†µê³„
    
    3. **Agentì˜ ì¥ì **
       - ìë™ ì˜ë„ ë¶„ë¥˜ (ë³„ë„ classify_user_intent ë¶ˆí•„ìš”)
       - ë³µì¡í•œ ì§ˆë¬¸ ì²˜ë¦¬ (ì—¬ëŸ¬ ë„êµ¬ ì¡°í•© ê°€ëŠ¥)
       - ëŒ€í™” ë§¥ë½ ìœ ì§€ (ì„¸ì…˜ ê¸°ë°˜ ë©”ëª¨ë¦¬)
    
    4. **í´ë°± ì²˜ë¦¬**
       - LangGraph ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
    
    =========================================================================
    """
    
    # ë¦¬ì†ŒìŠ¤ í™•ì¸
    if vectorstore is None or shelter_df is None:
        return LocationExtractResponse(success=False, message="ì„œë²„ ì´ˆê¸°í™”ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ì¿¼ë¦¬ ìœ íš¨ì„± ê²€ì‚¬
    query = request.query.strip()
    if not query:
        return LocationExtractResponse(success=False, message="ì…ë ¥ ë¬¸ì¥ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    print(f"[API] ì‚¬ìš©ì ì¿¼ë¦¬: '{query}'")
    
    # =========================================================================
    # ì¿¼ë¦¬ ìœ í˜• ë¶„ë¥˜: ë‹¨ìˆœ ëŒ€í”¼ì†Œ ìœ„ì¹˜ ì§ˆë¬¸ vs ë³µì¡í•œ ì§ˆë¬¸
    # =========================================================================
    # ë‹¨ìˆœ ì§ˆë¬¸: "ê°•ë‚¨ì—­ ê·¼ì²˜ ëŒ€í”¼ì†Œ", "ëª…ë™ ëŒ€í”¼ì†Œ ì–´ë””ì•¼" â†’ ì§€ë„ í‘œì‹œìš© ì¢Œí‘œ/ëŒ€í”¼ì†Œ ë°°ì—´ ë°˜í™˜
    # ë³µì¡í•œ ì§ˆë¬¸: "ê°•ë‚¨ì—­ì¸ë° ì§€ì§„ ë‚˜ë©´ ì–´ë””ë¡œ", "ëª…ë™ì—ì„œ í™”ì¬ ë°œìƒ ì‹œ ëŒ€ì²˜ë²•" â†’ Agent í…ìŠ¤íŠ¸ ì‘ë‹µ
    
    # ì¬ë‚œ ê´€ë ¨ í‚¤ì›Œë“œ ëª©ë¡
    disaster_keywords = [
        "ì§€ì§„", "í™ìˆ˜", "íƒœí’", "í™”ì¬", "í­ë°œ", "ì‚°ì‚¬íƒœ", "ì“°ë‚˜ë¯¸", 
        "í™”ì‚°", "ë°©ì‚¬ëŠ¥", "ê°€ìŠ¤", "ë¶•ê´´", "í…ŒëŸ¬", "ì „ìŸ",
        "í–‰ë™ìš”ë ¹", "ëŒ€ì²˜ë²•", "ëŒ€ì‘", "ì¡°ì¹˜", "ì£¼ì˜ì‚¬í•­", "ë°œìƒí•˜ë©´", "ë°œìƒ ì‹œ"
    ]
    
    # ì§ˆë¬¸ì— ì¬ë‚œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    has_disaster_context = any(keyword in query for keyword in disaster_keywords)
    
    # ë‹¨ìˆœ ëŒ€í”¼ì†Œ ìœ„ì¹˜ ì§ˆë¬¸ì¸ì§€ í™•ì¸
    shelter_keywords = ["ëŒ€í”¼ì†Œ", "í”¼ë‚œì†Œ", "í”¼ë‚œì²˜", "ê·¼ì²˜", "ì£¼ë³€", "ì–´ë””"]
    has_shelter_request = any(keyword in query for keyword in shelter_keywords)
    
    # ë¼ìš°íŒ… ê²°ì •
    use_agent = False
    
    if has_disaster_context:
        # ì¬ë‚œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ Agent ì‚¬ìš© (ë³µì¡í•œ ì§ˆë¬¸)
        use_agent = True
        print(f"[INFO] ì¬ë‚œ ë§¥ë½ ê°ì§€ â†’ LangGraph Agent ì‚¬ìš©")
    elif not has_shelter_request:
        # ëŒ€í”¼ì†Œ ê´€ë ¨ í‚¤ì›Œë“œë„ ì—†ê³  ì¬ë‚œ í‚¤ì›Œë“œë„ ì—†ìœ¼ë©´ Agent ì‚¬ìš© (ì¼ë°˜ ëŒ€í™” ë˜ëŠ” í†µê³„)
        use_agent = True
        print(f"[INFO] ì¼ë°˜ ì§ˆë¬¸ ê°ì§€ â†’ LangGraph Agent ì‚¬ìš©")
    else:
        # ëŒ€í”¼ì†Œ í‚¤ì›Œë“œë§Œ ìˆìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ë‹¨ìˆœ ìœ„ì¹˜ ì§ˆë¬¸)
        use_agent = False
        print(f"[INFO] ë‹¨ìˆœ ëŒ€í”¼ì†Œ ìœ„ì¹˜ ì§ˆë¬¸ ê°ì§€ â†’ ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ì§€ë„ í‘œì‹œ)")
    
    # =========================================================================
    # LangGraph Agent ì‚¬ìš© (ë³µì¡í•œ ì§ˆë¬¸ ì²˜ë¦¬)
    # =========================================================================
    if use_agent and langgraph_app is not None:
        try:
            print(f"[INFO] LangGraph Agentë¡œ ì²˜ë¦¬ ì‹œì‘")
            
            # ì„¸ì…˜ ID ìƒì„± (ìš”ì²­ë³„ ê³ ìœ  ID)
            session_id = f"session_{hash(query) % 100000}"
            config = {"configurable": {"thread_id": session_id}}
            
            # Agent ì‹¤í–‰
            # - Agentê°€ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ë„êµ¬ ì„ íƒ
            # - search_shelter, search_guideline ë“± ì ì ˆí•œ ë„êµ¬ ì‹¤í–‰
            # - ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¡°í•©í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥
            result = langgraph_app.invoke(
                {"messages": [HumanMessage(content=query)]},
                config=config
            )
            
            # Agentì˜ ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
            bot_response = result["messages"][-1].content
            print(f"[INFO] LangGraph Agent ì‘ë‹µ ì™„ë£Œ (ê¸¸ì´: {len(bot_response)})")
            
            # Agent ì‘ë‹µì„ LocationExtractResponse í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            # - í…ìŠ¤íŠ¸ ì‘ë‹µ í˜•ì‹ (messageì— í¬í•¨)
            # - ì¢Œí‘œ/ëŒ€í”¼ì†Œ ë°°ì—´ì€ ë¹„ì–´ìˆìŒ (ì§€ë„ í‘œì‹œ ë¶ˆê°€)
            return LocationExtractResponse(
                success=True,
                location=None,
                coordinates=None,
                shelters=[],
                total_count=0,
                message=bot_response
            )
            
        except Exception as e:
            print(f"[ERROR] LangGraph Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            print(f"[INFO] ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ í´ë°±")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ì•„ë˜ ê¸°ì¡´ ë¡œì§ìœ¼ë¡œ í´ë°±
    
    elif use_agent and langgraph_app is None:
        print(f"[WARNING] LangGraph Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ, ê¸°ì¡´ ë¡œì§ ì‚¬ìš©")
    
    # =========================================================================
    # ê¸°ì¡´ ë¡œì§ (LangGraph ì‹¤íŒ¨ ì‹œ í´ë°±)
    # =========================================================================
    
    # -----------------------
    # 1ì°¨: LLM ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
    # -----------------------
    intent = classify_user_intent(query)
    print(f"[API] ë¶„ë¥˜ëœ ì˜ë„: '{intent}'")
    
    # -----------------------
    # 2ì°¨: ì˜ë„ë³„ ì²˜ë¦¬ ë¡œì§
    # -----------------------
    
    # CASE 1: ì¼ë°˜ ëŒ€í™”
    if intent == "general_chat":
        print(f"[API] general_chat ì²˜ë¦¬")
        return LocationExtractResponse(
            success=True,
            message="ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ëŒ€í”¼ì†Œ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤. ì§€ì—­ëª…ì„ ì…ë ¥í•˜ì‹œë©´ ì£¼ë³€ ëŒ€í”¼ì†Œë¥¼ ì°¾ì•„ë“œë¦¬ê³ , ì¬ë‚œ ìƒí™©ì— ëŒ€í•œ í–‰ë™ìš”ë ¹ë„ ì•ˆë‚´í•´ ë“œë¦½ë‹ˆë‹¤."
        )
    
    # CASE 2: ì¬ë‚œí–‰ë™ìš”ë ¹ ê´€ë ¨ ì§ˆë¬¸
    elif intent == "disaster_guide":
        # Vector DBì—ì„œ ì¬ë‚œí–‰ë™ìš”ë ¹ ë¬¸ì„œ ê²€ìƒ‰
        print(f"[DEBUG] ì¬ë‚œí–‰ë™ìš”ë ¹ ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        
        # filterë¥¼ ì‚¬ìš©í•˜ì—¬ disaster_guideline íƒ€ì…ë§Œ ê²€ìƒ‰
        try:
            results = vectorstore.similarity_search(
                query, 
                k=5,
                filter={"type": "disaster_guideline"}
            )
            print(f"[DEBUG] disaster_guideline í•„í„°ë§ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
        except:
            # filter ì§€ì› ì•ˆ ë˜ë©´ ì „ì²´ ê²€ìƒ‰ í›„ í•„í„°ë§
            all_results = vectorstore.similarity_search(query, k=20)
            results = [doc for doc in all_results if doc.metadata.get("type") == "disaster_guideline"]
            print(f"[DEBUG] ì „ì²´ ê²€ìƒ‰ í›„ í•„í„°ë§ ê²°ê³¼: {len(results)}ê°œ")
        
        # ê²€ìƒ‰ ê²°ê³¼ ë””ë²„ê¹…
        for i, doc in enumerate(results[:3]):
            doc_type = doc.metadata.get("type", "NONE")
            category = doc.metadata.get("category", "N/A")
            keyword = doc.metadata.get("keyword", "N/A")
            print(f"[DEBUG] ë¬¸ì„œ {i+1}: type={doc_type}, category={category}, keyword={keyword}")
            print(f"[DEBUG]   ë‚´ìš©: {doc.page_content[:150]}...")
        
        # ì¬ë‚œí–‰ë™ìš”ë ¹ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not results or len(results) == 0:
            print("[ERROR] VectorStoreì— disaster_guideline ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")
            return LocationExtractResponse(
                success=False, 
                message="ì¬ë‚œí–‰ë™ìš”ë ¹ ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            )
        
        # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ì„ íƒ
        disaster_doc = results[0]
        
        print(f"[DEBUG] ì„ íƒëœ ì¬ë‚œë¬¸ì„œ - category: {disaster_doc.metadata.get('category')}, keyword: {disaster_doc.metadata.get('keyword')}")
        print(f"[DEBUG] ë¬¸ì„œ ê¸¸ì´: {len(disaster_doc.page_content)}")
        
        # ì‘ë‹µ ë©”ì‹œì§€ êµ¬ì„± (ì¹´í…Œê³ ë¦¬ì™€ í‚¤ì›Œë“œ ì •ë³´ í¬í•¨)
        category = disaster_doc.metadata.get('category', '')
        keyword = disaster_doc.metadata.get('keyword', '')
        header = f"ğŸ“‹ {category} - {keyword}\n\n" if category and keyword else ""
        
        return LocationExtractResponse(
            success=True,
            location=None,
            coordinates=None,
            shelters=[],
            total_count=0,
            message=header + disaster_doc.page_content[:1500]  # ë‹µë³€ ê¸¸ì´ ì¦ê°€
        )
        
    # CASE 3: ëŒ€í”¼ì†Œ ê´€ë ¨ ì§ˆë¬¸
    elif intent == "find_shelter":
        print(f"[API] find_shelter ì²˜ë¦¬ ì‹œì‘ - query: '{query}'")
        
        # =====================================================================
        # STEP 1: ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ìˆœìˆ˜ ì§€ëª…ë§Œ ì¶”ì¶œ (ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°)
        # =====================================================================
        # ì˜ˆ: "ê°•ë‚¨ì—­ ëŒ€í”¼ì†Œ ì•Œë ¤ì¤˜" -> "ê°•ë‚¨ì—­"
        # ì˜ˆ: "ëª…ë™ ê·¼ì²˜ í”¼ë‚œì†Œ" -> "ëª…ë™"
        location_query = query
        
        # ëŒ€í”¼ì†Œ ê´€ë ¨ í‚¤ì›Œë“œ ì œê±° ë¦¬ìŠ¤íŠ¸
        remove_keywords = [
            "ëŒ€í”¼ì†Œ", "í”¼ë‚œì†Œ", "í”¼ë‚œì²˜", "ê·¼ì²˜", "ì£¼ë³€", "ê°€ê¹Œìš´", "ì–´ë””", "ìœ„ì¹˜",
            "ì°¾ì•„ì¤˜", "ì•Œë ¤ì¤˜", "ê²€ìƒ‰", "ë³´ì—¬ì¤˜", "ìˆì–´", "ëŠ”?", "ì€?", "?", "!",
            "ì¢€", "ìš”", "ì£¼ì„¸ìš”", "í•´ì¤˜", "í•´ì£¼ì„¸ìš”", "ìˆë‚˜ìš”", "ìˆì–´ìš”"
        ]
        
        for keyword in remove_keywords:
            location_query = location_query.replace(keyword, "")
        
        # ê³µë°± ì •ë¦¬ (ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ í†µí•©)
        location_query = " ".join(location_query.split()).strip()
        
        print(f"[DEBUG] ì •ì œëœ ìœ„ì¹˜ ì¿¼ë¦¬: '{location_query}'")
        
        # ì •ì œ í›„ ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
        if not location_query:
            location_query = query
            print(f"[DEBUG] ì •ì œ ê²°ê³¼ê°€ ë¹„ì–´ìˆì–´ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©")
        
        # =====================================================================
        # STEP 2: ì¹´ì¹´ì˜¤ ë¡œì»¬ API í‚¤ í™•ì¸
        # =====================================================================
        kakao_key = os.getenv("KAKAO_REST_API_KEY")
        if not kakao_key:
            print(f"[ERROR] KAKAO_REST_API_KEY ì—†ìŒ")
            return LocationExtractResponse(success=False, message="KAKAO_REST_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # =====================================================================
        # STEP 3: ì—¬ëŸ¬ ì§€ëª…ì´ í¬í•¨ëœ ê²½ìš° ìš°ì„ ìˆœìœ„ íŒë‹¨
        # =====================================================================
        # ì˜ˆ: "ì ì‹¤ ë¡¯ë°ì›”ë“œ" -> "ë¡¯ë°ì›”ë“œ" ìš°ì„  ì„ íƒ (ê´€ê´‘ëª…ì†Œ)
        # ìš°ì„ ìˆœìœ„: 1=ê´€ê´‘ëª…ì†Œ/ë¬¸í™”ì‹œì„¤, 2=êµí†µì‹œì„¤(ì—­), 3=í–‰ì •êµ¬ì—­, 4=ê¸°íƒ€
        location_parts = location_query.split()
        selected_location = location_query
        
        if len(location_parts) > 1:
            print(f"[DEBUG] ì—¬ëŸ¬ ì§€ëª… ê°ì§€: {location_parts}, ì¹´ì¹´ì˜¤ APIë¡œ ìš°ì„ ìˆœìœ„ íŒë‹¨")
            
            url = "https://dapi.kakao.com/v2/local/search/keyword.json"
            headers = {"Authorization": f"KakaoAK {kakao_key}"}
            
            best_candidate = None
            best_priority = 999
            
            # ì¹´í…Œê³ ë¦¬ë³„ ìš°ì„ ìˆœìœ„ ì •ì˜
            priority_categories = {
                1: ["ê´€ê´‘ëª…ì†Œ", "ë¬¸í™”ì‹œì„¤", "ì—¬ê°€ì‹œì„¤", "ê³µê³µê¸°ê´€", "í…Œë§ˆíŒŒí¬"],
                2: ["êµí†µ,ìˆ˜ì†¡", "ì§€í•˜ì² ì—­"],
                3: ["í–‰ì •êµ¬ì—­"],
            }
            
            # ê° ì§€ëª…ì„ ì¹´ì¹´ì˜¤ APIë¡œ ê²€ìƒ‰í•˜ì—¬ ì¹´í…Œê³ ë¦¬ í™•ì¸
            for part in location_parts:
                resp = requests.get(url, headers=headers, params={"query": part, "size": 5})
                if resp.status_code == 200:
                    docs = resp.json().get("documents", [])
                    if docs:
                        doc = docs[0]
                        category_name = doc.get("category_name", "")
                        print(f"[DEBUG] '{part}' ê²€ìƒ‰ ê²°ê³¼ - category: {category_name}")
                        
                        # ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„ íŒë‹¨
                        priority = 4  # ê¸°ë³¸ê°’ (ê¸°íƒ€)
                        for pri, keywords in priority_categories.items():
                            if any(keyword in category_name for keyword in keywords):
                                priority = pri
                                break
                        
                        # ë” ë†’ì€ ìš°ì„ ìˆœìœ„(ë‚®ì€ ìˆ«ì)ë©´ ì„ íƒ
                        if priority < best_priority:
                            best_priority = priority
                            best_candidate = part
                            print(f"[DEBUG] ìš°ì„ ìˆœìœ„ {priority}: '{part}' ì„ íƒ (category: {category_name})")
            
            # ìš°ì„ ìˆœìœ„ê°€ ê°€ì¥ ë†’ì€ ì§€ëª… ì„ íƒ
            if best_candidate:
                selected_location = best_candidate
                print(f"[DEBUG] ìµœì¢… ì„ íƒëœ ìœ„ì¹˜: '{selected_location}' (ìš°ì„ ìˆœìœ„: {best_priority})")
            else:
                # API ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ ì§€ëª… ì‚¬ìš©
                selected_location = location_parts[0]
                print(f"[DEBUG] API ê²€ìƒ‰ ì‹¤íŒ¨, ì²« ë²ˆì§¸ ì§€ëª… ì‚¬ìš©: '{selected_location}'")
        
        location_query = selected_location
        
        # =====================================================================
        # STEP 4: ì¹´ì¹´ì˜¤ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ìœ„ì¹˜ ê²€ìƒ‰ (ìœ„/ê²½ë„ ì¢Œí‘œ íšë“)
        # =====================================================================
        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {"Authorization": f"KakaoAK {kakao_key}"}
        params = {"query": location_query, "size": 1}
        
        print(f"[DEBUG] ì¹´ì¹´ì˜¤ API ìµœì¢… ê²€ìƒ‰ - query: '{location_query}'")
        resp = requests.get(url, headers=headers, params=params)
        print(f"[DEBUG] ì¹´ì¹´ì˜¤ API ì‘ë‹µ - status: {resp.status_code}")
        
        if resp.status_code != 200:
            return LocationExtractResponse(success=False, message=f"ì¹´ì¹´ì˜¤ API ì˜¤ë¥˜: {resp.status_code}")
            
        data = resp.json()
        print(f"[DEBUG] ì¹´ì¹´ì˜¤ API ê²°ê³¼ ê°œìˆ˜: {len(data.get('documents', []))}")
        
        # =====================================================================
        # ì¹´ì¹´ì˜¤ API ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ LangGraph Agentë¥¼ ì‚¬ìš©í•œ ëŒ€í”¼ì†Œ ê²€ìƒ‰
        # =====================================================================
        if not data.get("documents"):
            print(f"[WARNING] ì¹´ì¹´ì˜¤ APIì—ì„œ '{location_query}' ìœ„ì¹˜ë¥¼ ì°¾ì§€ ëª»í•¨")
            print(f"[INFO] LangGraph Agentë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í”¼ì†Œ ê²€ìƒ‰ ì‹œë„")
            
            # LangGraph Agentê°€ ì´ˆê¸°í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if langgraph_app is None:
                print(f"[ERROR] LangGraph Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return LocationExtractResponse(
                    success=False, 
                    message=f"'{location_query}' ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§€ì—­ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."
                )
            
            try:
                # LangGraph Agentì—ê²Œ ëŒ€í”¼ì†Œ ê²€ìƒ‰ ìš”ì²­
                # - Agentê°€ search_shelter ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
                # - ì§ˆë¬¸ ì¬ì •ì˜(Query Rewriting)ë¥¼ í†µí•´ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
                # - Vector DB + BM25 ì•™ìƒë¸” ê²€ìƒ‰ìœ¼ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­ ê°•í™”
                print(f"[DEBUG] LangGraph Agent í˜¸ì¶œ - ì¿¼ë¦¬: '{query}'")
                
                # ì„¸ì…˜ ID ìƒì„± (ì„ì‹œ)
                session_id = f"temp_{hash(query) % 10000}"
                config = {"configurable": {"thread_id": session_id}}
                
                # Agent ì‹¤í–‰
                result = langgraph_app.invoke(
                    {"messages": [HumanMessage(content=query)]},
                    config=config
                )
                
                # Agentì˜ ì‘ë‹µ ì¶”ì¶œ
                bot_response = result["messages"][-1].content
                print(f"[DEBUG] LangGraph Agent ì‘ë‹µ (ê¸¸ì´: {len(bot_response)})")
                
                # Agent ì‘ë‹µì„ messageë¡œ ë°˜í™˜
                # - ì¢Œí‘œ ê¸°ë°˜ ê²€ìƒ‰ì´ ì•„ë‹Œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼
                # - shelters ë°°ì—´ì€ ë¹„ì–´ìˆì§€ë§Œ messageì— ëŒ€í”¼ì†Œ ì •ë³´ í¬í•¨
                return LocationExtractResponse(
                    success=True,
                    location=location_query,
                    coordinates=None,  # ì¢Œí‘œ ì •ë³´ ì—†ìŒ (ì¹´ì¹´ì˜¤ API ì‹¤íŒ¨)
                    shelters=[],  # Agent ì‘ë‹µì€ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ messageì— í¬í•¨
                    total_count=0,
                    message=bot_response  # Agentì˜ ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸
                )
                
            except Exception as e:
                print(f"[ERROR] LangGraph Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                return LocationExtractResponse(
                    success=False, 
                    message=f"'{location_query}' ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§€ì—­ëª…ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”."
                )
        
        # =====================================================================
        # ì¹´ì¹´ì˜¤ API ê²€ìƒ‰ ì„±ê³µ ì‹œ ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ì¢Œí‘œ ê¸°ë°˜ ëŒ€í”¼ì†Œ ê²€ìƒ‰)
        # =====================================================================
        # - ì¹´ì¹´ì˜¤ APIë¡œ íšë“í•œ ìœ„/ê²½ë„ ì¢Œí‘œ ì‚¬ìš©
        # - Haversine ê³µì‹ìœ¼ë¡œ ì‚¬ìš©ì ìœ„ì¹˜ â†” ëŒ€í”¼ì†Œ ê°„ ì§ì„  ê±°ë¦¬ ê³„ì‚°
        # - ê±°ë¦¬ìˆœ ì •ë ¬ í›„ ê°€ì¥ ê°€ê¹Œìš´ 5ê°œ ëŒ€í”¼ì†Œ ë°˜í™˜
        
        # ì¢Œí‘œ ì¶”ì¶œ
        place = data["documents"][0]
        lat = float(place["y"])  # ìœ„ë„
        lon = float(place["x"])  # ê²½ë„
        place_name = place.get("place_name", location_query)
        
        print(f"[DEBUG] ì¢Œí‘œ ì¶”ì¶œ ì„±ê³µ - place_name: {place_name}, lat: {lat}, lon: {lon}")
        
        # =====================================================================
        # STEP 5: VectorStoreì—ì„œ ëª¨ë“  ëŒ€í”¼ì†Œ ë°ì´í„° ê°€ì ¸ì™€ì„œ ê±°ë¦¬ ê³„ì‚°
        # =====================================================================
        import math
        
        def haversine(lat1, lon1, lat2, lon2):
            """
            Haversine ê³µì‹: êµ¬ë©´ìƒì˜ ë‘ ì  ì‚¬ì´ì˜ ìµœë‹¨ ê±°ë¦¬ ê³„ì‚°
            
            Args:
                lat1, lon1: ì²« ë²ˆì§¸ ì ì˜ ìœ„ë„/ê²½ë„ (ì‚¬ìš©ì ìœ„ì¹˜)
                lat2, lon2: ë‘ ë²ˆì§¸ ì ì˜ ìœ„ë„/ê²½ë„ (ëŒ€í”¼ì†Œ ìœ„ì¹˜)
            
            Returns:
                float: ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ (ë‹¨ìœ„: km)
            """
            R = 6371  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)
            phi1, phi2 = math.radians(lat1), math.radians(lat2)
            d_phi = math.radians(lat2 - lat1)
            d_lambda = math.radians(lon2 - lon1)
            a = math.sin(d_phi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(d_lambda/2)**2
            return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        # VectorStoreì—ì„œ shelter íƒ€ì… ë¬¸ì„œë§Œ í•„í„°ë§í•˜ì—¬ ê°€ì ¸ì˜¤ê¸°
        # - filter: {"type": "shelter"} ì¡°ê±´ìœ¼ë¡œ ëŒ€í”¼ì†Œ ë°ì´í„°ë§Œ ì¶”ì¶œ
        all_data = vectorstore.get(where={"type": "shelter"})
        all_metadatas = all_data.get('metadatas', [])
        
        print(f"[DEBUG] VectorStoreì—ì„œ {len(all_metadatas)}ê°œ ëŒ€í”¼ì†Œ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜´")
        
        shelters = []
        
        # ê° ëŒ€í”¼ì†Œì˜ ì¢Œí‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ê±°ë¦¬ ê³„ì‚°
        for metadata in all_metadatas:
            # shelter íƒ€ì… ë¬¸ì„œë§Œ ì²˜ë¦¬ (ì´ì¤‘ í™•ì¸)
            if metadata.get('type') != 'shelter':
                continue
                
            # ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ (documents.pyì—ì„œ ì˜ë¬¸ í‚¤ë¡œ ì €ì¥ë¨)
            s_lat = metadata.get('lat')  # ëŒ€í”¼ì†Œ ìœ„ë„
            s_lon = metadata.get('lon')  # ëŒ€í”¼ì†Œ ê²½ë„
            
            if s_lat is not None and s_lon is not None:
                try:
                    s_lat = float(s_lat)
                    s_lon = float(s_lon)
                    
                    # Haversine ê³µì‹ìœ¼ë¡œ ì‚¬ìš©ì ìœ„ì¹˜ â†” ëŒ€í”¼ì†Œ ê°„ ê±°ë¦¬ ê³„ì‚°
                    distance = haversine(lat, lon, s_lat, s_lon)
                    
                    # ëŒ€í”¼ì†Œ ì •ë³´ ê°ì²´ ìƒì„±
                    shelter_info = {
                        'name': metadata.get('facility_name', 'N/A'),  # ì‹œì„¤ëª…
                        'address': metadata.get('address', 'N/A'),     # ì£¼ì†Œ
                        'lat': s_lat,                                   # ìœ„ë„
                        'lon': s_lon,                                   # ê²½ë„
                        'capacity': int(metadata.get('capacity', 0)),  # ìˆ˜ìš©ì¸ì›
                        'distance': distance                            # ê±°ë¦¬ (km)
                    }
                    shelters.append(shelter_info)
                    
                except (ValueError, TypeError):
                    # ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ í•´ë‹¹ ëŒ€í”¼ì†ŒëŠ” ê±´ë„ˆëœ€
                    continue
        
        print(f"[DEBUG] ì´ {len(shelters)}ê°œ ëŒ€í”¼ì†Œì˜ ê±°ë¦¬ ê³„ì‚° ì™„ë£Œ")
        
        # =====================================================================
        # STEP 6: ê±°ë¦¬ìˆœ ì •ë ¬ í›„ ìƒìœ„ 5ê°œ ë°˜í™˜
        # =====================================================================
        shelters.sort(key=lambda x: x['distance'])  # ê±°ë¦¬ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        top_shelters = shelters[:5]  # ê°€ì¥ ê°€ê¹Œìš´ 5ê°œ ì„ íƒ
        
        print(f"[DEBUG] ìƒìœ„ 5ê°œ ëŒ€í”¼ì†Œ ì„ íƒ ì™„ë£Œ")
        for i, s in enumerate(top_shelters):
            print(f"[DEBUG]   {i+1}. {s['name']} ({s['distance']:.2f}km)")
        
        # ê²°ê³¼ ë°˜í™˜
        # - success: True (ê²€ìƒ‰ ì„±ê³µ)
        # - location: ê²€ìƒ‰ëœ ì¥ì†Œëª… (ì˜ˆ: "ê°•ë‚¨ì—­")
        # - coordinates: (ìœ„ë„, ê²½ë„) íŠœí”Œ
        # - shelters: ê°€ì¥ ê°€ê¹Œìš´ ëŒ€í”¼ì†Œ 5ê°œ ë¦¬ìŠ¤íŠ¸
        # - total_count: VectorDBì— ì €ì¥ëœ ì „ì²´ ëŒ€í”¼ì†Œ ê°œìˆ˜
        return LocationExtractResponse(
            success=True,
            location=place_name,
            coordinates=(lat, lon),
            shelters=top_shelters,
            total_count=len(all_metadatas),
            message="OK"
        )
        
    # CASE 3: ê¸°íƒ€ ì§ˆë¬¸
    else:
        return LocationExtractResponse(success=False, message="ëŒ€í”¼ì†Œ/ì¬ë‚œí–‰ë™ìš”ë ¹ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹™ë‹ˆë‹¤.")


# -----------------------------------------------------------------------------
# 5. ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
# -----------------------------------------------------------------------------

# CORS (Cross-Origin Resource Sharing) ì„¤ì •
# ëª¨ë“  ë„ë©”ì¸ì—ì„œì˜ ìš”ì²­ì„ í—ˆìš© (ê°œë°œ í™˜ê²½ í¸ì˜ì„±)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  HTTP í—¤ë” í—ˆìš©
)


# -----------------------------------------------------------------------------
# 6. ì¶”ê°€ Request/Response ëª¨ë¸
# -----------------------------------------------------------------------------

class ChatRequest(BaseModel):
    query: str
    user_lat: Optional[float] = None # ì‚¬ìš©ìì˜ ìœ„ë„ (ì„ íƒ ì‚¬í•­)
    user_lon: Optional[float] = None # ì‚¬ìš©ìì˜ ê²½ë„ (ì„ íƒ ì‚¬í•­)


class ChatResponse(BaseModel):
    response: str
    shelters: List[Dict]
    location: Dict


class ShelterSearchRequest(BaseModel):
    location: str # ê²€ìƒ‰í•  ì§€ëª…
    top_k: int = 5 # ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜


# -----------------------------------------------------------------------------
# 7. ê¸°ë³¸ API ì—”ë“œí¬ì¸íŠ¸ (ì›¹, ìƒíƒœí™•ì¸)
# -----------------------------------------------------------------------------

@app.get("/")
async def read_root():
    """
    ë©”ì¸ í˜ì´ì§€ (ì›¹ ì¸í„°í˜ì´ìŠ¤)
    - shelter_1.0.html íŒŒì¼ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    template_path = Path(__file__).parent / "shelter_1.0.html"
    if not template_path.exists():
        raise HTTPException(
            status_code=404, 
            detail=f"í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_path}"
        )
    return FileResponse(str(template_path))


@app.get("/api/health")
async def health_check():
    """
    ì„œë²„ í—¬ìŠ¤ ì²´í¬
    - ë¡œë“œë°¸ëŸ°ì„œë‚˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì—ì„œ ì„œë²„ ìƒì¡´ ì—¬ë¶€ë¥¼ í™•ì¸í•  ë•Œ ì‚¬ìš©
    """
    return {
        "status": "ok",
        "vectorstore_ready": vectorstore is not None,
        "shelter_data_ready": shelter_df is not None
    }


@app.get("/api/status")
async def get_api_status():
    """
    ìƒì„¸ API ìƒíƒœ í™•ì¸
    - DB ë¡œë“œ ìƒíƒœ, LLM API í‚¤ ì¡´ì¬ ì—¬ë¶€ ë“± ì‹œìŠ¤í…œ ì „ë°˜ì ì¸ ìƒíƒœ ë°˜í™˜
    """
    # OPENAI_API_KEY í™•ì¸ (í™˜ê²½ë³€ìˆ˜)
    openai_available = bool(os.getenv("OPENAI_API_KEY"))
    
    return {
        "server_ready": True,
        "llm_available": openai_available,
        "vectorstore_ready": vectorstore is not None,
        "total_shelters": len(shelter_df) if shelter_df is not None else 0,
        "shelter_data_ready": shelter_df is not None
    }


# -----------------------------------------------------------------------------
# 8. ëŒ€í”¼ì†Œ ì¡°íšŒ/ê²€ìƒ‰ API (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - /api/location/extractë¡œ í†µí•©ë¨)
# -----------------------------------------------------------------------------

# @app.get("/api/shelters/all") - ì‚¬ìš© ì•ˆ í•¨
# @app.post("/api/shelters/search") - ì‚¬ìš© ì•ˆ í•¨

@app.get("/api/shelters/nearest")
async def get_nearest_shelters(lat: float, lon: float, k: int = 5):
    """
    í˜„ìœ„ì¹˜ ê¸°ì¤€ ê°€ì¥ ê°€ê¹Œìš´ ëŒ€í”¼ì†Œ ê²€ìƒ‰
    - VectorStoreì˜ ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ ê±°ë¦¬ ê³„ì‚° ë°©ì‹ ì‚¬ìš©
    - shelter íƒ€ì… ë¬¸ì„œë“¤ì˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì¢Œí‘œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê±°ë¦¬ ê³„ì‚°
    """
    print(f"[API] get_nearest_shelters í˜¸ì¶œë¨: lat={lat}, lon={lon}, k={k}")
    print(f"[API] shelter_df ìƒíƒœ: {shelter_df is not None}")
    print(f"[API] vectorstore ìƒíƒœ: {vectorstore is not None}")
    import math

    # í•˜ë²„ì‚¬ì¸(Haversine) ê³µì‹: êµ¬ë©´ìƒì˜ ë‘ ì  ì‚¬ì´ì˜ ìµœë‹¨ ê±°ë¦¬ ê³„ì‚°
    def haversine(lat1, lon1, lat2, lon2):
        R = 6371  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)
        phi1, phi2 = math.radians(lat1), math.radians(lat2)
        d_phi = math.radians(lat2 - lat1)
        d_lambda = math.radians(lon2 - lon1)
        a = math.sin(d_phi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(d_lambda/2)**2
        return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))

    # VectorStore ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if vectorstore is None:
        print("[DEBUG] VectorStoreê°€ ì—†ì–´ì„œ shelter_dfë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        # shelter_dfë¡œ í´ë°± (ê¸°ì¡´ ë¡œì§)
        if shelter_df is None:
            return {"user_location": {"lat": lat, "lon": lon}, "shelters": [], "total_count": 0}
        
        shelters = []
        for _, row in shelter_df.iterrows():
            s_lat = row.get('ìœ„ë„(EPSG4326)')
            s_lon = row.get('ê²½ë„(EPSG4326)')
            
            if s_lat is not None and s_lon is not None:
                try:
                    s_lat = float(s_lat)
                    s_lon = float(s_lon)
                    distance = haversine(lat, lon, s_lat, s_lon)
                    
                    shelters.append({
                        'name': row.get('ì‹œì„¤ëª…', 'N/A'),
                        'address': row.get('ë„ë¡œëª…ì „ì²´ì£¼ì†Œ', 'N/A'),
                        'lat': s_lat,
                        'lon': s_lon,
                        'capacity': int(row.get('ìµœëŒ€ìˆ˜ìš©ì¸ì›', 0)) if pd.notna(row.get('ìµœëŒ€ìˆ˜ìš©ì¸ì›')) else 0,
                        'distance': distance
                    })
                except Exception:
                    continue
        
        shelters.sort(key=lambda x: x['distance'])
        top_shelters = shelters[:k]
        
        return {
            "user_location": {"lat": lat, "lon": lon},
            "shelters": top_shelters,
            "total_count": len(top_shelters)
        }
    
    # VectorStoreë¥¼ ì‚¬ìš©í•œ ëŒ€í”¼ì†Œ ê²€ìƒ‰
    try:
        print(f"[DEBUG] vectorstore ê°ì²´ íƒ€ì…: {type(vectorstore)}")
        print(f"[DEBUG] vectorstore._collectionì´ ìˆëŠ”ì§€: {hasattr(vectorstore, '_collection')}")
        
        # ì»¬ë ‰ì…˜ì˜ ì „ì²´ ë¬¸ì„œ ìˆ˜ í™•ì¸
        collection_count = vectorstore._collection.count()
        print(f"[DEBUG] vectorstore ì»¬ë ‰ì…˜ì— {collection_count}ê°œ ë¬¸ì„œê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        
        # 1. VectorStoreì—ì„œ shelter íƒ€ì… ë¬¸ì„œë§Œ í•„í„°ë§í•˜ì—¬ ê°€ì ¸ì˜¤ê¸°
        # where ì¡°ê±´ìœ¼ë¡œ shelter íƒ€ì…ë§Œ í•„í„°ë§
        all_data = vectorstore.get(
            where={"type": "shelter"}
        )
        print(f"[DEBUG] vectorstore.get() ê²°ê³¼: {type(all_data)}, í‚¤ë“¤: {all_data.keys() if isinstance(all_data, dict) else 'dictê°€ ì•„ë‹˜'}")
        
        all_metadatas = all_data.get('metadatas', [])
        
        print(f"[DEBUG] VectorStoreì—ì„œ {len(all_metadatas)}ê°œ ë¬¸ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        
        # ë””ë²„ê¹…: shelter íƒ€ì… ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
        shelter_count = sum(1 for m in all_metadatas if m.get('type') == 'shelter')
        print(f"[DEBUG] VectorStoreì— shelter íƒ€ì… ë¬¸ì„œê°€ {shelter_count}ê°œ ìˆìŠµë‹ˆë‹¤.")
        
        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ shelter ë©”íƒ€ë°ì´í„° í‚¤ í™•ì¸
        if all_metadatas:
            first_shelter = next((m for m in all_metadatas if m.get('type') == 'shelter'), None)
            if first_shelter:
                print(f"[DEBUG] ì²« ë²ˆì§¸ shelter ë©”íƒ€ë°ì´í„° í‚¤ë“¤: {list(first_shelter.keys())}")
                print(f"[DEBUG] facility_name ê°’: {first_shelter.get('facility_name', 'KEY ì—†ìŒ')}")
                print(f"[DEBUG] address ê°’: {first_shelter.get('address', 'KEY ì—†ìŒ')}")
        
        shelters = []
        
        # 2. shelter íƒ€ì… ë¬¸ì„œë“¤ë§Œ í•„í„°ë§í•˜ê³  ê±°ë¦¬ ê³„ì‚°
        for metadata in all_metadatas:
            # shelter íƒ€ì… ë¬¸ì„œë§Œ ì²˜ë¦¬
            if metadata.get('type') != 'shelter':
                continue
                
            # ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ (documents.pyì—ì„œ ì˜ë¬¸ í‚¤ë¡œ ì €ì¥ë¨)
            s_lat = metadata.get('lat')
            s_lon = metadata.get('lon')
            
            if s_lat is not None and s_lon is not None:
                try:
                    s_lat = float(s_lat)
                    s_lon = float(s_lon)
                    distance = haversine(lat, lon, s_lat, s_lon)
                    
                    # ëŒ€í”¼ì†Œ ì •ë³´ êµ¬ì„± (documents.pyì˜ ì˜ë¬¸ í‚¤ ì‚¬ìš©)
                    shelter_info = {
                        'name': metadata.get('facility_name', 'N/A'),
                        'address': metadata.get('address', 'N/A'),
                        'lat': s_lat,
                        'lon': s_lon,
                        'capacity': int(metadata.get('capacity', 0)),
                        'distance': distance
                    }
                    shelters.append(shelter_info)
                    
                except (ValueError, TypeError) as e:
                    print(f"[WARNING] ì¢Œí‘œ ë³€í™˜ ì˜¤ë¥˜: {e}")
                    continue
        
        print(f"[DEBUG] ìœ íš¨í•œ ëŒ€í”¼ì†Œ {len(shelters)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # 3. ê±°ë¦¬ìˆœ ì •ë ¬ ë° ìƒìœ„ kê°œ ì„ íƒ
        shelters.sort(key=lambda x: x['distance'])
        top_shelters = shelters[:k]
        
        return {
            "user_location": {"lat": lat, "lon": lon},
            "shelters": top_shelters,
            "total_count": len(top_shelters)
        }
        
    except Exception as e:
        print(f"[ERROR] VectorStore ì‚¬ìš© ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return {"user_location": {"lat": lat, "lon": lon}, "shelters": [], "total_count": 0}


# -----------------------------------------------------------------------------
# 9. LangGraph Agent ê¸°ë°˜ ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------------------------------------------

@app.post("/api/chatbot", response_model=ChatbotResponse)
async def chatbot_endpoint(request: ChatbotRequest):
    """
    LangGraph Agent ê¸°ë°˜ ê³ ê¸‰ ì±—ë´‡ ì—”ë“œí¬ì¸íŠ¸
    
    íŠ¹ì§•:
    - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Vector + BM25)
    - ì§ˆë¬¸ ì¬ì •ì˜ (Query Rewriting)
    - Agent + Tools ì•„í‚¤í…ì²˜
    - í†µê³„ ê¸°ëŠ¥ (ìˆ˜ìš©ì¸ì› ì§‘ê³„)
    - ì„¸ì…˜ ê¸°ë°˜ ëŒ€í™” ê¸°ë¡ ìœ ì§€
    
    Args:
        request: ChatbotRequest (message, session_id)
    
    Returns:
        ChatbotResponse (response, session_id)
    """
    try:
        if langgraph_app is None:
            raise HTTPException(
                status_code=503, 
                detail="ì±—ë´‡ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
            )
        
        # ì„¸ì…˜ ì„¤ì •
        config = {"configurable": {"thread_id": request.session_id}}
        
        # LangGraph Agent ì‹¤í–‰
        result = langgraph_app.invoke(
            {"messages": [HumanMessage(content=request.message)]},
            config=config
        )
        
        # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì¶”ì¶œ
        bot_response = result["messages"][-1].content
        
        return ChatbotResponse(
            response=bot_response,
            session_id=request.session_id
        )
    
    except HTTPException:
        raise
    except Exception as e:
        print(f"[ERROR] ì±—ë´‡ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


# -----------------------------------------------------------------------------
# 10. ì„œë²„ ì‹¤í–‰
# -----------------------------------------------------------------------------

if __name__ == "__main__":
    # HTTPS ì§€ì› ì„œë²„ ì‹¤í–‰
    # SSL ì¸ì¦ì„œ ê²½ë¡œ ì„¤ì •
    cert_dir = "shelter_chatbot/cert"
    cert_file = f"{cert_dir}/cert.pem"
    key_file = f"{cert_dir}/key.pem"
    
    # ì¸ì¦ì„œ íŒŒì¼ ì¡´ì¬ í™•ì¸
    import os
    if os.path.exists(cert_file) and os.path.exists(key_file):
        print(f"[INFO] SSL ì¸ì¦ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ HTTPS ì„œë²„ ì‹œì‘")
        # print(f"[INFO] ì£¼ì†Œ: https://61.78.100.228:8443/")
        print(f"[INFO] ì£¼ì†Œ: https://222.106.254.193:8443/")
        
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8443,
            ssl_keyfile=key_file,
            ssl_certfile=cert_file,
            reload=False,
            log_level="info"
        )
    else:
        print(f"[WARNING] SSL ì¸ì¦ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"[INFO] HTTP ì„œë²„ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8443,
            reload=False,
            log_level="info"
        )